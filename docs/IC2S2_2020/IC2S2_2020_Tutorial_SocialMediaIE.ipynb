{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IC2S2 2020 Tutorial - SocialMediaIE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GhBlfX8N3NXd",
        "2laV8zau3eGO",
        "GpXXPrJZ4I5B"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxa-1bCVGZmt",
        "colab_type": "text"
      },
      "source": [
        "# [IC2S2 2020 Tutorial on Hands on advanced machine learning for information extraction from tweets tasks, data, and open source tools](https://socialmediaie.github.io/tutorials/IC2S2_2020/)\n",
        "\n",
        "* Author: [Shubhanshu Mishra](http://shubhanshu.com/)\n",
        "* Contact: [https://twitter.com/TheShubhanshu](https://twitter.com/TheShubhanshu)\n",
        "\n",
        "More details at: https://socialmediaie.github.io/tutorials/IC2S2_2020/\n",
        "\n",
        "This notebook demonstrates the usage of an open-source tool we have built called [SocialMediaIE](https://github.com/socialmediaie/SocialMediaIE), which uses multi-task learning to do state-of-the-art performance on English language social media data like tweets. You can find more details about the tool at: https://github.com/socialmediaie/SocialMediaIE\n",
        "\n",
        "If you have feedback or requests for features in SocialMediaIE please raise an issue at: https://github.com/socialmediaie/SocialMediaIE/issues\n",
        "\n",
        "If you would like to use SocialMediaIE on your local machine please follow the instructions at: https://socialmediaie.github.io/tutorials/IC2S2_2020/#software-setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhBlfX8N3NXd",
        "colab_type": "text"
      },
      "source": [
        "# Setup instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2laV8zau3eGO",
        "colab_type": "text"
      },
      "source": [
        "## Install Anaconda and setup system path\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4mEBWwOm78s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15acfd90-ec48-43ff-9f4c-907a5787c21e"
      },
      "source": [
        "!which python # should return /usr/local/bin/python\n",
        "!python --version\n",
        "!echo $PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/python\n",
            "Python 3.6.9\n",
            "/env/python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zuoB_x2nLj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e909217-6bc0-4575-ba45-eba4ba951eac"
      },
      "source": [
        "%%bash\n",
        "# Based on this article:\n",
        "# https://towardsdatascience.com/conda-google-colab-75f7c867a522\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "if [ ! -f $MINICONDA_INSTALLER_SCRIPT ]; then\n",
        "  wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "  chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "  export PYTHONPATH=\"\"\n",
        "  ./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX\n",
        "  conda install --channel defaults conda python=3.6 --yes\n",
        "  conda update --channel defaults --all --yes\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    conda-4.8.3                |           py36_0         3.0 MB\n",
            "    chardet-3.0.4              |        py36_1003         197 KB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    cffi-1.14.0                |   py36he30daa8_1         226 KB\n",
            "    pycosat-0.6.3              |   py36h7b6447c_0         107 KB\n",
            "    six-1.15.0                 |             py_0          13 KB\n",
            "    cryptography-2.9.2         |   py36h1ba5d50_0         626 KB\n",
            "    brotlipy-0.7.0             |py36h7b6447c_1000         348 KB\n",
            "    ncurses-6.2                |       he6710b0_1         1.1 MB\n",
            "    tqdm-4.47.0                |             py_0          62 KB\n",
            "    requests-2.24.0            |             py_0          54 KB\n",
            "    idna-2.10                  |             py_0          56 KB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    sqlite-3.32.3              |       h62c20be_0         2.0 MB\n",
            "    certifi-2020.6.20          |           py36_0         160 KB\n",
            "    openssl-1.1.1g             |       h7b6447c_0         3.8 MB\n",
            "    pycparser-2.20             |             py_2          94 KB\n",
            "    pysocks-1.7.1              |           py36_0          30 KB\n",
            "    ruamel_yaml-0.15.87        |   py36h7b6447c_1         256 KB\n",
            "    ca-certificates-2020.6.24  |                0         133 KB\n",
            "    conda-package-handling-1.6.1|   py36h7b6447c_0         886 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    python-3.6.10              |       h7579374_2        33.9 MB\n",
            "    wheel-0.34.2               |           py36_0          49 KB\n",
            "    urllib3-1.25.9             |             py_0          98 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    libedit-3.1.20191231       |       h14c3975_1         121 KB\n",
            "    pyopenssl-19.1.0           |             py_1          47 KB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    setuptools-49.2.0          |           py36_0         929 KB\n",
            "    ld_impl_linux-64-2.33.1    |       h53a641e_7         645 KB\n",
            "    pip-20.1.1                 |           py36_1         2.0 MB\n",
            "    readline-8.0               |       h7b6447c_0         428 KB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        67.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:          0.1-main               \n",
            "    brotlipy:               0.7.0-py36h7b6447c_1000\n",
            "    conda-package-handling: 1.6.1-py36h7b6447c_0   \n",
            "    ld_impl_linux-64:       2.33.1-h53a641e_7      \n",
            "    tqdm:                   4.47.0-py_0            \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2020.6.24-0            \n",
            "    certifi:                2018.4.16-py36_0        --> 2020.6.20-py36_0       \n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.0-py36he30daa8_1  \n",
            "    chardet:                3.0.4-py36h0f667ec_1    --> 3.0.4-py36_1003        \n",
            "    conda:                  4.5.4-py36_0            --> 4.8.3-py36_0           \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 2.9.2-py36h1ba5d50_0   \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 2.10-py_0              \n",
            "    libedit:                3.1.20170329-h6b74fdf_2 --> 3.1.20191231-h14c3975_1\n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2         \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0       \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0       \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.2-he6710b0_1         \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1g-h7b6447c_0      \n",
            "    pip:                    10.0.1-py36_0           --> 20.1.1-py36_1          \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py36h7b6447c_0   \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.20-py_2              \n",
            "    pyopenssl:              18.0.0-py36_0           --> 19.1.0-py_1            \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py36_0           \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.10-h7579374_2      \n",
            "    readline:               7.0-ha6073c6_4          --> 8.0-h7b6447c_0         \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.24.0-py_0            \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.87-py36h7b6447c_1 \n",
            "    setuptools:             39.2.0-py36_0           --> 49.2.0-py36_0          \n",
            "    six:                    1.11.0-py36h372c433_1   --> 1.15.0-py_0            \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.32.3-h62c20be_0      \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.10-hbc83047_0      \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.25.9-py_0            \n",
            "    wheel:                  0.31.1-py36_0           --> 0.34.2-py36_0          \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0       \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0       \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3      \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  asn1crypto-0.24.0-py36_0\n",
            "  conda-env-2.6.0-h36134e3_1\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-07-19 07:15:25--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2020-07-19 07:15:26--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 58.6M 1s\n",
            "    50K .......... .......... .......... .......... ..........  0% 3.75M 8s\n",
            "   100K .......... .......... .......... .......... ..........  0% 3.80M 10s\n",
            "   150K .......... .......... .......... .......... ..........  0% 3.75M 11s\n",
            "   200K .......... .......... .......... .......... ..........  0% 69.1M 9s\n",
            "   250K .......... .......... .......... .......... ..........  0%  148M 8s\n",
            "   300K .......... .......... .......... .......... ..........  0% 4.20M 8s\n",
            "   350K .......... .......... .......... .......... ..........  0% 61.9M 8s\n",
            "   400K .......... .......... .......... .......... ..........  0% 88.1M 7s\n",
            "   450K .......... .......... .......... .......... ..........  0% 24.3M 6s\n",
            "   500K .......... .......... .......... .......... ..........  0%  178M 6s\n",
            "   550K .......... .......... .......... .......... ..........  1%  133M 5s\n",
            "   600K .......... .......... .......... .......... ..........  1%  191M 5s\n",
            "   650K .......... .......... .......... .......... ..........  1% 55.3M 5s\n",
            "   700K .......... .......... .......... .......... ..........  1% 68.0M 4s\n",
            "   750K .......... .......... .......... .......... ..........  1% 6.68M 5s\n",
            "   800K .......... .......... .......... .......... ..........  1%  134M 4s\n",
            "   850K .......... .......... .......... .......... ..........  1% 49.3M 4s\n",
            "   900K .......... .......... .......... .......... ..........  1% 59.3M 4s\n",
            "   950K .......... .......... .......... .......... ..........  1% 62.0M 4s\n",
            "  1000K .......... .......... .......... .......... ..........  1%  117M 4s\n",
            "  1050K .......... .......... .......... .......... ..........  1% 57.4M 4s\n",
            "  1100K .......... .......... .......... .......... ..........  2% 86.8M 3s\n",
            "  1150K .......... .......... .......... .......... ..........  2% 52.1M 3s\n",
            "  1200K .......... .......... .......... .......... ..........  2% 59.6M 3s\n",
            "  1250K .......... .......... .......... .......... ..........  2%  124M 3s\n",
            "  1300K .......... .......... .......... .......... ..........  2% 65.2M 3s\n",
            "  1350K .......... .......... .......... .......... ..........  2% 76.8M 3s\n",
            "  1400K .......... .......... .......... .......... ..........  2% 36.0M 3s\n",
            "  1450K .......... .......... .......... .......... ..........  2%  170M 3s\n",
            "  1500K .......... .......... .......... .......... ..........  2%  138M 3s\n",
            "  1550K .......... .......... .......... .......... ..........  2% 57.0M 3s\n",
            "  1600K .......... .......... .......... .......... ..........  2% 63.9M 3s\n",
            "  1650K .......... .......... .......... .......... ..........  2%  120M 3s\n",
            "  1700K .......... .......... .......... .......... ..........  3% 93.5M 2s\n",
            "  1750K .......... .......... .......... .......... ..........  3%  119M 2s\n",
            "  1800K .......... .......... .......... .......... ..........  3% 78.7M 2s\n",
            "  1850K .......... .......... .......... .......... ..........  3%  174M 2s\n",
            "  1900K .......... .......... .......... .......... ..........  3% 65.5M 2s\n",
            "  1950K .......... .......... .......... .......... ..........  3%  137M 2s\n",
            "  2000K .......... .......... .......... .......... ..........  3%  123M 2s\n",
            "  2050K .......... .......... .......... .......... ..........  3% 96.7M 2s\n",
            "  2100K .......... .......... .......... .......... ..........  3% 74.9M 2s\n",
            "  2150K .......... .......... .......... .......... ..........  3%  147M 2s\n",
            "  2200K .......... .......... .......... .......... ..........  3%  109M 2s\n",
            "  2250K .......... .......... .......... .......... ..........  4%  133M 2s\n",
            "  2300K .......... .......... .......... .......... ..........  4%  111M 2s\n",
            "  2350K .......... .......... .......... .......... ..........  4% 88.3M 2s\n",
            "  2400K .......... .......... .......... .......... ..........  4%  159M 2s\n",
            "  2450K .......... .......... .......... .......... ..........  4% 26.9M 2s\n",
            "  2500K .......... .......... .......... .......... ..........  4%  136M 2s\n",
            "  2550K .......... .......... .......... .......... ..........  4%  125M 2s\n",
            "  2600K .......... .......... .......... .......... ..........  4%  156M 2s\n",
            "  2650K .......... .......... .......... .......... ..........  4%  167M 2s\n",
            "  2700K .......... .......... .......... .......... ..........  4%  143M 2s\n",
            "  2750K .......... .......... .......... .......... ..........  4%  141M 2s\n",
            "  2800K .......... .......... .......... .......... ..........  4%  164M 2s\n",
            "  2850K .......... .......... .......... .......... ..........  5%  136M 2s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  173M 2s\n",
            "  2950K .......... .......... .......... .......... ..........  5%  145M 2s\n",
            "  3000K .......... .......... .......... .......... ..........  5%  148M 2s\n",
            "  3050K .......... .......... .......... .......... ..........  5%  161M 2s\n",
            "  3100K .......... .......... .......... .......... ..........  5%  158M 2s\n",
            "  3150K .......... .......... .......... .......... ..........  5%  147M 2s\n",
            "  3200K .......... .......... .......... .......... ..........  5% 71.4M 2s\n",
            "  3250K .......... .......... .......... .......... ..........  5%  181M 2s\n",
            "  3300K .......... .......... .......... .......... ..........  5% 88.3M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  112M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  140M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  140M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6% 39.3M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  119M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  153M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  144M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  151M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6%  163M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6%  189M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6% 31.8M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6%  139M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7%  132M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7%  157M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7%  160M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7%  156M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7%  124M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7%  157M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7%  144M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7%  176M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7%  133M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7%  155M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7%  156M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7%  161M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8%  155M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8%  191M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8%  142M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8%  193M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8%  155M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8%  197M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8%  168M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8%  148M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8%  137M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8%  147M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8%  178M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9%  151M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9%  134M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9%  186M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  185M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  199M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  137M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  143M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  169M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  158M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9% 40.2M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  192M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9%  200M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  205M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  133M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  121M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  172M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  166M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  135M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10%  129M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  157M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  152M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10%  158M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  161M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  176M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  137M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11%  153M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11%  163M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11%  195M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11%  195M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11%  126M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11%  196M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11%  191M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11%  184M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11%  150M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11%  165M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12%  152M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12%  167M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12%  140M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12%  173M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12%  157M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12%  165M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12%  172M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12%  187M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12%  167M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12%  164M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12%  175M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13%  182M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13%  148M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13%  167M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13%  155M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13% 41.8M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13%  202M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  169M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  128M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  165M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  201M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  188M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14%  116M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14%  182M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  196M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14%  156M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  163M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  158M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  184M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  142M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14%  155M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14%  154M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14%  191M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  195M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  130M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15%  190M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15%  196M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15%  197M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 15%  118M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  169M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  164M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  144M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 15%  172M 1s\n",
            "  9000K .......... .......... .......... .......... .......... 15%  180M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  145M 1s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  161M 1s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  176M 1s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  187M 1s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  125M 1s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  175M 1s\n",
            "  9350K .......... .......... .......... .......... .......... 16%  168M 1s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  132M 1s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  186M 1s\n",
            "  9500K .......... .......... .......... .......... .......... 16%  204M 1s\n",
            "  9550K .......... .......... .......... .......... .......... 16%  163M 1s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  157M 1s\n",
            "  9650K .......... .......... .......... .......... .......... 16% 41.9M 1s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  151M 1s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  133M 1s\n",
            "  9800K .......... .......... .......... .......... .......... 17%  188M 1s\n",
            "  9850K .......... .......... .......... .......... .......... 17%  207M 1s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  171M 1s\n",
            "  9950K .......... .......... .......... .......... .......... 17%  123M 1s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  196M 1s\n",
            " 10050K .......... .......... .......... .......... .......... 17%  172M 1s\n",
            " 10100K .......... .......... .......... .......... .......... 17%  171M 1s\n",
            " 10150K .......... .......... .......... .......... .......... 17%  176M 1s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  164M 1s\n",
            " 10250K .......... .......... .......... .......... .......... 18%  197M 1s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  130M 1s\n",
            " 10350K .......... .......... .......... .......... .......... 18%  144M 1s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  194M 1s\n",
            " 10450K .......... .......... .......... .......... .......... 18%  167M 1s\n",
            " 10500K .......... .......... .......... .......... .......... 18%  156M 1s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  110M 1s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  174M 1s\n",
            " 10650K .......... .......... .......... .......... .......... 18%  189M 1s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  149M 1s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  160M 1s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  159M 1s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  139M 1s\n",
            " 10900K .......... .......... .......... .......... .......... 19%  178M 1s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  163M 1s\n",
            " 11000K .......... .......... .......... .......... .......... 19%  166M 1s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  137M 1s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  200M 1s\n",
            " 11150K .......... .......... .......... .......... .......... 19%  163M 1s\n",
            " 11200K .......... .......... .......... .......... .......... 19%  146M 1s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  177M 1s\n",
            " 11300K .......... .......... .......... .......... .......... 19%  190M 1s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  177M 1s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  147M 1s\n",
            " 11450K .......... .......... .......... .......... .......... 20%  196M 1s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  204M 1s\n",
            " 11550K .......... .......... .......... .......... .......... 20%  167M 1s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  140M 1s\n",
            " 11650K .......... .......... .......... .......... .......... 20%  172M 1s\n",
            " 11700K .......... .......... .......... .......... .......... 20% 41.9M 1s\n",
            " 11750K .......... .......... .......... .......... .......... 20%  175M 1s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  189M 1s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  197M 1s\n",
            " 11900K .......... .......... .......... .......... .......... 20%  148M 1s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  141M 1s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  197M 1s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  161M 1s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  161M 1s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  166M 1s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  153M 1s\n",
            " 12250K .......... .......... .......... .......... .......... 21%  146M 1s\n",
            " 12300K .......... .......... .......... .......... .......... 21%  178M 1s\n",
            " 12350K .......... .......... .......... .......... .......... 21%  144M 1s\n",
            " 12400K .......... .......... .......... .......... .......... 21%  188M 1s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  190M 1s\n",
            " 12500K .......... .......... .......... .......... .......... 21%  147M 1s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  166M 1s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  172M 1s\n",
            " 12650K .......... .......... .......... .......... .......... 22%  180M 1s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  145M 1s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  161M 1s\n",
            " 12800K .......... .......... .......... .......... .......... 22%  143M 1s\n",
            " 12850K .......... .......... .......... .......... .......... 22%  142M 1s\n",
            " 12900K .......... .......... .......... .......... .......... 22%  196M 1s\n",
            " 12950K .......... .......... .......... .......... .......... 22%  171M 1s\n",
            " 13000K .......... .......... .......... .......... .......... 22%  149M 1s\n",
            " 13050K .......... .......... .......... .......... .......... 22%  158M 1s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  161M 1s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  159M 1s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  168M 1s\n",
            " 13250K .......... .......... .......... .......... .......... 23%  195M 1s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  179M 1s\n",
            " 13350K .......... .......... .......... .......... .......... 23%  172M 1s\n",
            " 13400K .......... .......... .......... .......... .......... 23%  199M 1s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  193M 1s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  186M 1s\n",
            " 13550K .......... .......... .......... .......... .......... 23%  164M 1s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  200M 1s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  154M 1s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  112M 1s\n",
            " 13750K .......... .......... .......... .......... .......... 24% 41.5M 1s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  208M 1s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  149M 1s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  171M 1s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  152M 1s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  176M 1s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  167M 1s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  157M 1s\n",
            " 14150K .......... .......... .......... .......... .......... 24%  136M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 24%  147M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  195M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  175M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  118M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  196M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  189M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  164M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  158M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 25%  148M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  171M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  158M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  136M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  150M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  179M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26%  154M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26%  176M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26%  148M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26%  184M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26%  166M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26%  143M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  165M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  197M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26%  200M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26%  164M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  194M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  158M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27%  162M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27%  168M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  144M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  149M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27%  164M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27%  135M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27% 40.4M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  200M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27%  193M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28%  166M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28%  198M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  138M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28%  167M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28%  143M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  159M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28%  174M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28%  141M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28%  129M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28%  196M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28%  171M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28%  186M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29%  131M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29%  159M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29%  164M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29%  192M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29%  125M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29%  170M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29%  180M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29%  198M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  155M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29%  149M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  184M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  176M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30%  146M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30%  178M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  197M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  197M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  143M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  188M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30%  155M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  136M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30%  159M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  159M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  200M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  155M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31%  131M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31%  196M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31% 41.5M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  165M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31%  162M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  151M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31%  184M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  147M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  151M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  154M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  147M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  110M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  154M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  194M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  156M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32%  145M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32%  147M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32%  169M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32%  150M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32%  157M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32%  172M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33%  187M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33%  180M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33%  163M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  131M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33%  187M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33%  163M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33%  176M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33%  157M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33%  191M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  162M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33%  175M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  150M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34%  138M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34%  155M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34%  147M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34%  149M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  193M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34%  186M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34%  156M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34%  138M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34%  188M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  189M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34% 43.2M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35%  131M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  160M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  168M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35%  167M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  136M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35%  157M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  159M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  195M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35%  166M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  178M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35%  144M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  171M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  135M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36%  175M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36%  147M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  194M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36%  164M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36%  199M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  154M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36%  153M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36%  150M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36%  169M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  156M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37%  183M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37%  162M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37%  139M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37%  196M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37%  198M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37%  118M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37%  154M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  197M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37%  153M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37%  164M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  198M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38%  177M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38%  124M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38%  135M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38%  199M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38%  167M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38%  195M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38% 40.9M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38%  157M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38%  190M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38%  167M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38%  136M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38%  152M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39%  194M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39%  204M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39%  158M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39%  137M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39%  172M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39%  205M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39%  180M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39%  157M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39%  177M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39%  230M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39%  147M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40%  249M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40% 44.6M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40%  169M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40%  126M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40%  229M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  147M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40%  148M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40%  186M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  223M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  140M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  144M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40%  176M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41%  158M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41%  187M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41%  218M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  147M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  131M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41%  175M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  197M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41% 41.9M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41%  212M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41%  168M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41%  163M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42%  158M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42%  139M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42%  166M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  180M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  130M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  198M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42%  184M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42%  148M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42%  116M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  189M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  229M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  151M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  157M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  230M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43%  185M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  222M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  165M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43%  217M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43%  171M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43%  155M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  122M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  180M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  191M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44%  159M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  124M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44%  200M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44%  230M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  237M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44%  124M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  160M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  199M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44%  212M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  158M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  196M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  143M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45%  167M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45%  161M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45% 43.2M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45%  206M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  196M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45%  157M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  163M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45%  124M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  150M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45% 99.8M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  187M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  195M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46%  174M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46%  130M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46%  146M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  188M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  175M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  143M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46%  167M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46%  197M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46%  197M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46%  141M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  167M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  201M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  155M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47%  153M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47%  173M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  183M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  144M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  136M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  193M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47%  176M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47%  200M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47%  129M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48%  157M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48%  195M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48%  202M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48%  181M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48%  178M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48%  151M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48%  165M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48%  127M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  193M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48% 43.2M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48%  195M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  170M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49%  166M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49%  152M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  161M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49%  126M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49%  170M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  159M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  159M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  146M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49%  162M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  162M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50%  173M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  147M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  152M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  174M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  198M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  166M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50% 89.3M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50% 71.6M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  197M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50%  209M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  173M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  171M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51%  199M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51%  189M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  206M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  192M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  167M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51%  180M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  211M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  222M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51%  232M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  184M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  209M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52%  158M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52%  186M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52% 37.6M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52%  204M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52%  222M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52%  232M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52%  196M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52%  221M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52%  158M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  186M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  179M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  154M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  201M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  206M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  129M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  171M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53%  194M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53%  182M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53%  125M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  159M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  145M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  142M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  132M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  170M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  134M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54%  162M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54%  179M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54%  142M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54% 40.2M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54%  199M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54%  121M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  163M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54%  170M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54%  197M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  170M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  195M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  192M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  146M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  132M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  215M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  203M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55% 39.7M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55%  164M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55%  202M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55%  162M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  149M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56%  146M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  183M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  152M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56%  147M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  146M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56%  164M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56%  174M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  150M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  155M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  181M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  182M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57%  148M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57%  134M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  199M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57%  202M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  157M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  142M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57%  166M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  208M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  187M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57%  167M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  172M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57%  165M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  198M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  156M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  169M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58%  148M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  176M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  148M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  159M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  200M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  198M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58%  120M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  142M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  199M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  203M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59% 40.7M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  193M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  157M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  137M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  145M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  174M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59% 98.2M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59%  170M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59%  126M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59%  176M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  161M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60%  138M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  161M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  191M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  146M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60%  144M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  157M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60%  196M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  136M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60%  150M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  175M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  201M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  185M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  188M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61%  133M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61%  169M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  181M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61%  145M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61%  152M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61%  159M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  188M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61%  200M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61%  117M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62%  189M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62%  165M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  152M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62%  145M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  193M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  197M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  192M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62%  159M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62% 40.4M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62%  198M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  158M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63%  173M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63%  170M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63%  153M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  164M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63%  139M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  169M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63%  162M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63%  176M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63%  177M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  186M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  145M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64%  168M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64%  158M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64%  187M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  150M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  170M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64%  147M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  150M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64%  193M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  189M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  121M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  192M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  154M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65%  164M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65%  157M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65%  162M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  179M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  159M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65%  147M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65%  161M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  166M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  167M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  148M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  191M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  198M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66%  197M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66%  154M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  189M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66% 43.5M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  154M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  137M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  167M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  172M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  161M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  137M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  173M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67%  197M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  154M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67%  177M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  161M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67%  160M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67%  141M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67%  157M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  157M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  164M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  166M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  142M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  191M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  198M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  154M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  149M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  170M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68%  155M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  138M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68%  152M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  143M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  180M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  164M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  159M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69%  162M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69%  185M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  179M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  173M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  182M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  145M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69%  196M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69%  148M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  189M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  200M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69% 42.2M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70%  140M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  157M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70%  175M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  159M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  122M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  166M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70%  163M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  183M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  147M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  171M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70%  159M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71%  168M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  134M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  164M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  158M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  171M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  149M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  189M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71%  170M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  171M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  131M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71%  170M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  165M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  154M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72%  160M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  174M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  200M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  136M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  167M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  201M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72%  187M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  162M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72%  175M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  135M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73% 91.4M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  165M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  141M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73%  167M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  178M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  164M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73% 32.2M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  158M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73%  147M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  151M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73%  145M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  147M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74%  168M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  159M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  139M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74%  146M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74% 90.0M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74%  189M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74%  119M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74% 90.2M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  147M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  154M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  130M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  147M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  159M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  155M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75%  151M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75%  186M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  164M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75%  137M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75%  162M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75%  181M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  185M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  134M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76%  127M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76%  154M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  156M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  190M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  152M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76%  188M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  195M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  184M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  159M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  190M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  199M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76%  125M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  155M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77% 41.1M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77%  158M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  159M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  143M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  164M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  150M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  164M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  154M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  149M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  195M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  198M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78%  115M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  160M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78%  195M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78%  130M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78%  132M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  163M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78%  183M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  188M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  165M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78%  171M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  145M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  193M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  177M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  185M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79%  130M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79%  165M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  117M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  142M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  180M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  196M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79%  163M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  196M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  191M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  184M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  157M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80%  194M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  140M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  152M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  143M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80%  166M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80% 39.8M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  164M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80%  136M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81%  157M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  164M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  165M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81%  138M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81%  167M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  193M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  158M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81%  123M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  191M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81%  195M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  132M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81%  154M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  199M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82%  180M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  192M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  166M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  143M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  157M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82%  190M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  172M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  139M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82%  151M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82%  169M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83%  136M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83%  157M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  196M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  195M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  159M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  193M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83%  203M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  195M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  151M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  163M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83%  163M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  132M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84%  153M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  159M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84%  143M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84% 42.0M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84%  135M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84%  155M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84%  159M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  179M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84%  173M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84%  179M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84%  165M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85%  157M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85%  149M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85%  187M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85%  168M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85%  169M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85%  145M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  197M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  200M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85%  186M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85%  134M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85%  148M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85%  170M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86%  165M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86%  145M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86%  158M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86%  143M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86%  166M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86%  135M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  179M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86%  199M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  194M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86%  169M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86%  191M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  197M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  203M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  159M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  143M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87%  188M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87%  196M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  149M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  199M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87% 88.1M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87%  171M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87% 38.9M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  170M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  126M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  177M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  175M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  135M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  176M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  188M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  158M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88%  156M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88%  169M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88%  173M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88%  163M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89%  194M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89%  197M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89%  138M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  128M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89%  162M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89%  172M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89%  153M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  154M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  166M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89%  163M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  150M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  139M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  179M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90%  194M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90%  202M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  166M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  189M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90%  199M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90%  196M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  113M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  192M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90%  200M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  158M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91%  128M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  155M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  151M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  137M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91% 39.2M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  148M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  148M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91%  167M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91%  138M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  144M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  196M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  201M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  122M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92%  193M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  164M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92%  192M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  165M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92%  199M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92%  148M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  155M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92%  141M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  167M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92%  159M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  188M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93%  156M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93%  170M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93%  146M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93%  156M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93%  156M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93%  180M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93%  197M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  199M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93%  174M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93%  184M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94%  198M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  160M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  125M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  180M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94%  166M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  158M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  150M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  180M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  185M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  156M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94%  133M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95% 42.2M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95%  156M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95%  192M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  131M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  172M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  175M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  198M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95%  131M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95%  158M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  198M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  201M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  182M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  185M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  175M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  162M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96%  117M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  172M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  158M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  164M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  137M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  179M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  164M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  176M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  176M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  196M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  167M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97%  193M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97%  155M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97%  196M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97%  182M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  190M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  166M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  188M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  190M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  196M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  169M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  188M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98%  198M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  209M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98%  163M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98%  186M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98% 45.0M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98%  197M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98%  167M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  203M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98%  185M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  199M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  162M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  187M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  191M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  194M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  168M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  187M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99%  187M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  198M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  167M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  187M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100%  195M=0.4s\n",
            "\n",
            "2020-07-19 07:15:26 (126 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "\rconda-4.8.3          |  3.0 MB |            |   0% \rconda-4.8.3          |  3.0 MB | #######8   |  79% \rconda-4.8.3          |  3.0 MB | ########## | 100% \n",
            "\rchardet-3.0.4        |  197 KB |            |   0% \rchardet-3.0.4        |  197 KB | #########7 |  97% \rchardet-3.0.4        |  197 KB | ########## | 100% \n",
            "\rlibstdcxx-ng-9.1.0   |  4.0 MB |            |   0% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #######6   |  77% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #########5 |  96% \rlibstdcxx-ng-9.1.0   |  4.0 MB | ########## | 100% \n",
            "\rcffi-1.14.0          |  226 KB |            |   0% \rcffi-1.14.0          |  226 KB | ########## | 100% \n",
            "\rpycosat-0.6.3        |  107 KB |            |   0% \rpycosat-0.6.3        |  107 KB | ########## | 100% \n",
            "\rsix-1.15.0           |   13 KB |            |   0% \rsix-1.15.0           |   13 KB | ########## | 100% \n",
            "\rcryptography-2.9.2   |  626 KB |            |   0% \rcryptography-2.9.2   |  626 KB | ########3  |  84% \rcryptography-2.9.2   |  626 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  348 KB |            |   0% \rbrotlipy-0.7.0       |  348 KB | ########## | 100% \n",
            "\rncurses-6.2          |  1.1 MB |            |   0% \rncurses-6.2          |  1.1 MB | #######8   |  78% \rncurses-6.2          |  1.1 MB | #########7 |  97% \rncurses-6.2          |  1.1 MB | ########## | 100% \n",
            "\rtqdm-4.47.0          |   62 KB |            |   0% \rtqdm-4.47.0          |   62 KB | ########## | 100% \n",
            "\rrequests-2.24.0      |   54 KB |            |   0% \rrequests-2.24.0      |   54 KB | ########## | 100% \n",
            "\ridna-2.10            |   56 KB |            |   0% \ridna-2.10            |   56 KB | ########## | 100% \n",
            "\rtk-8.6.10            |  3.2 MB |            |   0% \rtk-8.6.10            |  3.2 MB | #######7   |  78% \rtk-8.6.10            |  3.2 MB | #########4 |  94% \rtk-8.6.10            |  3.2 MB | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    |    3 KB |            |   0% \r_libgcc_mutex-0.1    |    3 KB | ########## | 100% \n",
            "\rsqlite-3.32.3        |  2.0 MB |            |   0% \rsqlite-3.32.3        |  2.0 MB | #######8   |  78% \rsqlite-3.32.3        |  2.0 MB | #########8 |  98% \rsqlite-3.32.3        |  2.0 MB | ########## | 100% \n",
            "\rcertifi-2020.6.20    |  160 KB |            |   0% \rcertifi-2020.6.20    |  160 KB | ########## | 100% \n",
            "\ropenssl-1.1.1g       |  3.8 MB |            |   0% \ropenssl-1.1.1g       |  3.8 MB | #######6   |  77% \ropenssl-1.1.1g       |  3.8 MB | #########4 |  94% \ropenssl-1.1.1g       |  3.8 MB | ########## | 100% \n",
            "\rpycparser-2.20       |   94 KB |            |   0% \rpycparser-2.20       |   94 KB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   30 KB |            |   0% \rpysocks-1.7.1        |   30 KB | ########## | 100% \n",
            "\rruamel_yaml-0.15.87  |  256 KB |            |   0% \rruamel_yaml-0.15.87  |  256 KB | #########6 |  97% \rruamel_yaml-0.15.87  |  256 KB | ########## | 100% \n",
            "\rca-certificates-2020 |  133 KB |            |   0% \rca-certificates-2020 |  133 KB | ########## | 100% \n",
            "\rconda-package-handli |  886 KB |            |   0% \rconda-package-handli |  886 KB | ########8  |  89% \rconda-package-handli |  886 KB | ########## | 100% \n",
            "\rxz-5.2.5             |  438 KB |            |   0% \rxz-5.2.5             |  438 KB | #########  |  90% \rxz-5.2.5             |  438 KB | ########## | 100% \n",
            "\rlibgcc-ng-9.1.0      |  8.1 MB |            |   0% \rlibgcc-ng-9.1.0      |  8.1 MB | #######5   |  75% \rlibgcc-ng-9.1.0      |  8.1 MB | #########7 |  98% \rlibgcc-ng-9.1.0      |  8.1 MB | ########## | 100% \n",
            "\rpython-3.6.10        | 33.9 MB |            |   0% \rpython-3.6.10        | 33.9 MB | ##3        |  23% \rpython-3.6.10        | 33.9 MB | #####3     |  54% \rpython-3.6.10        | 33.9 MB | #######5   |  75% \rpython-3.6.10        | 33.9 MB | ########9  |  89% \rpython-3.6.10        | 33.9 MB | #########8 |  99% \rpython-3.6.10        | 33.9 MB | ########## | 100% \n",
            "\rwheel-0.34.2         |   49 KB |            |   0% \rwheel-0.34.2         |   49 KB | ########## | 100% \n",
            "\rurllib3-1.25.9       |   98 KB |            |   0% \rurllib3-1.25.9       |   98 KB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\rlibedit-3.1.20191231 |  121 KB |            |   0% \rlibedit-3.1.20191231 |  121 KB | ########## | 100% \n",
            "\rpyopenssl-19.1.0     |   47 KB |            |   0% \rpyopenssl-19.1.0     |   47 KB | ########## | 100% \n",
            "\rzlib-1.2.11          |  120 KB |            |   0% \rzlib-1.2.11          |  120 KB | ########## | 100% \n",
            "\rsetuptools-49.2.0    |  929 KB |            |   0% \rsetuptools-49.2.0    |  929 KB | ########1  |  82% \rsetuptools-49.2.0    |  929 KB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  645 KB |            |   0% \rld_impl_linux-64-2.3 |  645 KB | ########8  |  89% \rld_impl_linux-64-2.3 |  645 KB | ########## | 100% \n",
            "\rpip-20.1.1           |  2.0 MB |            |   0% \rpip-20.1.1           |  2.0 MB | #######8   |  79% \rpip-20.1.1           |  2.0 MB | #########2 |  93% \rpip-20.1.1           |  2.0 MB | ########## | 100% \n",
            "\rreadline-8.0         |  428 KB |            |   0% \rreadline-8.0         |  428 KB | #########3 |  94% \rreadline-8.0         |  428 KB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwG89f-RnAjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32328c5a-edf4-4c76-fd58-adca20b1c2ea"
      },
      "source": [
        "!which conda # should return /usr/local/bin/conda\n",
        "!conda --version # should return 4.5.4\n",
        "!python --version # now returns Python 3.6.10 :: Anaconda, Inc."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/conda\n",
            "conda 4.8.3\n",
            "Python 3.6.10 :: Anaconda, Inc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilsHC1SJ0FPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c3de0c-09fe-48e9-8a56-b84f5e9778cd"
      },
      "source": [
        "! pip --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pip 20.1.1 from /usr/local/lib/python3.6/site-packages/pip (python 3.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2eqLWM6pQbk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a94f2c-7101-44cf-9c79-f64e79060d5b"
      },
      "source": [
        "%%bash\n",
        "if [ ! -d \"SocialMediaIE\" ]; then\n",
        "  git clone https://github.com/socialmediaie/SocialMediaIE.git\n",
        "  conda env update -n base -f ./SocialMediaIE/environment.yml\n",
        "  # pip install -e ./SocialMediaIE/.\n",
        "  #! pip install -e git+https://github.com/socialmediaie/SocialMediaIE.git#egg=SocialMediaIE\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\rjupyter_client-6.1.6 | 84 KB     |            |   0% \rjupyter_client-6.1.6 | 84 KB     | ########## | 100% \n",
            "\rtbb-2020.0           | 1.1 MB    |            |   0% \rtbb-2020.0           | 1.1 MB    | ########## | 100% \n",
            "\rpexpect-4.8.0        | 82 KB     |            |   0% \rpexpect-4.8.0        | 82 KB     | ########## | 100% \n",
            "\rnumpy-1.15.4         | 46 KB     |            |   0% \rnumpy-1.15.4         | 46 KB     | ########## | 100% \n",
            "\rlibllvm9-9.0.1       | 21.0 MB   |            |   0% \rlibllvm9-9.0.1       | 21.0 MB   | ####9      |  50% \rlibllvm9-9.0.1       | 21.0 MB   | ########## | 100% \n",
            "\ripython_genutils-0.2 | 39 KB     |            |   0% \ripython_genutils-0.2 | 39 KB     | ########## | 100% \n",
            "\rtraitlets-4.3.3      | 140 KB    |            |   0% \rtraitlets-4.3.3      | 140 KB    | ########## | 100% \n",
            "\rprompt-toolkit-3.0.5 | 245 KB    |            |   0% \rprompt-toolkit-3.0.5 | 245 KB    | ########## | 100% \n",
            "\rdecorator-4.4.2      | 14 KB     |            |   0% \rdecorator-4.4.2      | 14 KB     | ########## | 100% \n",
            "\rpython-dateutil-2.8. | 215 KB    |            |   0% \rpython-dateutil-2.8. | 215 KB    | ########## | 100% \n",
            "\rbackcall-0.2.0       | 15 KB     |            |   0% \rbackcall-0.2.0       | 15 KB     | ########## | 100% \n",
            "\rtornado-6.0.4        | 597 KB    |            |   0% \rtornado-6.0.4        | 597 KB    | ########## | 100% \n",
            "\rmkl-2020.1           | 129.0 MB  |            |   0% \rmkl-2020.1           | 129.0 MB  | 7          |   8% \rmkl-2020.1           | 129.0 MB  | #8         |  19% \rmkl-2020.1           | 129.0 MB  | ##9        |  29% \rmkl-2020.1           | 129.0 MB  | ####       |  41% \rmkl-2020.1           | 129.0 MB  | #####1     |  52% \rmkl-2020.1           | 129.0 MB  | ######2    |  63% \rmkl-2020.1           | 129.0 MB  | #######2   |  73% \rmkl-2020.1           | 129.0 MB  | ########1  |  82% \rmkl-2020.1           | 129.0 MB  | #########1 |  91% \rmkl-2020.1           | 129.0 MB  | ########## | 100% \n",
            "\rjupyter_core-4.6.3   | 71 KB     |            |   0% \rjupyter_core-4.6.3   | 71 KB     | ########## | 100% \n",
            "\rblas-1.0             | 6 KB      |            |   0% \rblas-1.0             | 6 KB      | ########## | 100% \n",
            "\rnumpy-base-1.15.4    | 3.4 MB    |            |   0% \rnumpy-base-1.15.4    | 3.4 MB    | ########## | 100% \n",
            "\rpygments-2.6.1       | 654 KB    |            |   0% \rpygments-2.6.1       | 654 KB    | ########## | 100% \n",
            "\ripython-7.16.1       | 999 KB    |            |   0% \ripython-7.16.1       | 999 KB    | ########## | 100% \n",
            "\rscikit-learn-0.20.2  | 4.4 MB    |            |   0% \rscikit-learn-0.20.2  | 4.4 MB    | ########## | 100% \n",
            "\rwcwidth-0.2.5        | 29 KB     |            |   0% \rwcwidth-0.2.5        | 29 KB     | ########## | 100% \n",
            "\rmkl_random-1.1.1     | 327 KB    |            |   0% \rmkl_random-1.1.1     | 327 KB    | ########## | 100% \n",
            "\rpython_abi-3.6       | 4 KB      |            |   0% \rpython_abi-3.6       | 4 KB      | ########## | 100% \n",
            "\ripykernel-5.3.2      | 179 KB    |            |   0% \ripykernel-5.3.2      | 179 KB    | ########## | 100% \n",
            "\rninja-1.9.0          | 1.2 MB    |            |   0% \rninja-1.9.0          | 1.2 MB    | ########## | 100% \n",
            "\rllvmlite-0.33.0      | 17.3 MB   |            |   0% \rllvmlite-0.33.0      | 17.3 MB   | #####6     |  57% \rllvmlite-0.33.0      | 17.3 MB   | ########## | 100% \n",
            "\rmkl-service-2.3.0    | 219 KB    |            |   0% \rmkl-service-2.3.0    | 219 KB    | ########## | 100% \n",
            "\rlibsodium-1.0.18     | 244 KB    |            |   0% \rlibsodium-1.0.18     | 244 KB    | ########## | 100% \n",
            "\rscipy-1.2.1          | 13.7 MB   |            |   0% \rscipy-1.2.1          | 13.7 MB   | ######7    |  67% \rscipy-1.2.1          | 13.7 MB   | ########## | 100% \n",
            "\rlibgfortran-ng-7.3.0 | 1006 KB   |            |   0% \rlibgfortran-ng-7.3.0 | 1006 KB   | ########## | 100% \n",
            "\rpyzmq-19.0.1         | 460 KB    |            |   0% \rpyzmq-19.0.1         | 460 KB    | ########## | 100% \n",
            "\rpandas-1.0.5         | 7.8 MB    |            |   0% \rpandas-1.0.5         | 7.8 MB    | ########## | 100% \n",
            "\rintel-openmp-2020.1  | 780 KB    |            |   0% \rintel-openmp-2020.1  | 780 KB    | ########## | 100% \n",
            "\rzeromq-4.3.2         | 510 KB    |            |   0% \rzeromq-4.3.2         | 510 KB    | ########## | 100% \n",
            "\rjedi-0.17.1          | 921 KB    |            |   0% \rjedi-0.17.1          | 921 KB    | ########## | 100% \n",
            "\rnumba-0.50.1         | 3.1 MB    |            |   0% \rnumba-0.50.1         | 3.1 MB    | ########## | 100% \n",
            "\rptyprocess-0.6.0     | 23 KB     |            |   0% \rptyprocess-0.6.0     | 23 KB     | ########## | 100% \n",
            "\rpytorch-1.0.0        | 498.6 MB  |            |   0% \rpytorch-1.0.0        | 498.6 MB  |            |   0% \rpytorch-1.0.0        | 498.6 MB  |            |   1% \rpytorch-1.0.0        | 498.6 MB  | 3          |   4% \rpytorch-1.0.0        | 498.6 MB  | 6          |   7% \rpytorch-1.0.0        | 498.6 MB  | 8          |   9% \rpytorch-1.0.0        | 498.6 MB  | #          |  10% \rpytorch-1.0.0        | 498.6 MB  | #1         |  12% \rpytorch-1.0.0        | 498.6 MB  | #4         |  14% \rpytorch-1.0.0        | 498.6 MB  | #6         |  17% \rpytorch-1.0.0        | 498.6 MB  | #9         |  19% \rpytorch-1.0.0        | 498.6 MB  | ##1        |  21% \rpytorch-1.0.0        | 498.6 MB  | ##3        |  24% \rpytorch-1.0.0        | 498.6 MB  | ##6        |  27% \rpytorch-1.0.0        | 498.6 MB  | ##8        |  29% \rpytorch-1.0.0        | 498.6 MB  | ###        |  31% \rpytorch-1.0.0        | 498.6 MB  | ###3       |  33% \rpytorch-1.0.0        | 498.6 MB  | ###5       |  35% \rpytorch-1.0.0        | 498.6 MB  | ###7       |  37% \rpytorch-1.0.0        | 498.6 MB  | ###9       |  40% \rpytorch-1.0.0        | 498.6 MB  | ####2      |  43% \rpytorch-1.0.0        | 498.6 MB  | ####4      |  44% \rpytorch-1.0.0        | 498.6 MB  | ####5      |  46% \rpytorch-1.0.0        | 498.6 MB  | ####7      |  47% \rpytorch-1.0.0        | 498.6 MB  | ####8      |  49% \rpytorch-1.0.0        | 498.6 MB  | ####9      |  50% \rpytorch-1.0.0        | 498.6 MB  | #####      |  51% \rpytorch-1.0.0        | 498.6 MB  | #####3     |  54% \rpytorch-1.0.0        | 498.6 MB  | #####5     |  56% \rpytorch-1.0.0        | 498.6 MB  | #####7     |  58% \rpytorch-1.0.0        | 498.6 MB  | #####9     |  60% \rpytorch-1.0.0        | 498.6 MB  | ######1    |  62% \rpytorch-1.0.0        | 498.6 MB  | ######4    |  65% \rpytorch-1.0.0        | 498.6 MB  | ######6    |  67% \rpytorch-1.0.0        | 498.6 MB  | ######8    |  69% \rpytorch-1.0.0        | 498.6 MB  | #######    |  71% \rpytorch-1.0.0        | 498.6 MB  | #######3   |  74% \rpytorch-1.0.0        | 498.6 MB  | #######6   |  76% \rpytorch-1.0.0        | 498.6 MB  | #######7   |  78% \rpytorch-1.0.0        | 498.6 MB  | ########   |  80% \rpytorch-1.0.0        | 498.6 MB  | ########2  |  83% \rpytorch-1.0.0        | 498.6 MB  | ########4  |  84% \rpytorch-1.0.0        | 498.6 MB  | ########6  |  86% \rpytorch-1.0.0        | 498.6 MB  | ########8  |  88% \rpytorch-1.0.0        | 498.6 MB  | #########  |  90% \rpytorch-1.0.0        | 498.6 MB  | #########2 |  92% \rpytorch-1.0.0        | 498.6 MB  | #########4 |  94% \rpytorch-1.0.0        | 498.6 MB  | #########6 |  97% \rpytorch-1.0.0        | 498.6 MB  | #########8 |  99% \rpytorch-1.0.0        | 498.6 MB  | ########## | 100% \n",
            "\rpytz-2020.1          | 184 KB    |            |   0% \rpytz-2020.1          | 184 KB    | ########## | 100% \n",
            "\rpickleshare-0.7.5    | 13 KB     |            |   0% \rpickleshare-0.7.5    | 13 KB     | ########## | 100% \n",
            "\rparso-0.7.0          | 72 KB     |            |   0% \rparso-0.7.0          | 72 KB     | ########## | 100% \n",
            "\rumap-learn-0.4.2     | 108 KB    |            |   0% \rumap-learn-0.4.2     | 108 KB    | #4         |  15% \rumap-learn-0.4.2     | 108 KB    | ########## | 100% \n",
            "\rmkl_fft-1.1.0        | 144 KB    |            |   0% \rmkl_fft-1.1.0        | 144 KB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Ran pip subprocess with arguments:\n",
            "['/usr/local/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting allennlp==0.8.3\n",
            "  Downloading allennlp-0.8.3-py3-none-any.whl (5.6 MB)\n",
            "Collecting flask>=1.0.2\n",
            "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting spacy<2.2,>=2.0\n",
            "  Downloading spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl (30.8 MB)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/site-packages (from allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (0.20.2)\n",
            "Collecting sqlparse>=0.2.4\n",
            "  Downloading sqlparse-0.3.1-py2.py3-none-any.whl (40 kB)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "  Downloading jsonnet-0.16.0.tar.gz (256 kB)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/site-packages (from allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (1.2.1)\n",
            "Collecting flaky\n",
            "  Downloading flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.19 in /usr/local/lib/python3.6/site-packages (from allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (4.47.0)\n",
            "Collecting gevent>=1.3.6\n",
            "  Downloading gevent-20.6.2-cp36-cp36m-manylinux2010_x86_64.whl (5.3 MB)\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
            "Collecting responses>=0.7\n",
            "  Downloading responses-0.10.15-py2.py3-none-any.whl (15 kB)\n",
            "Collecting awscli>=1.11.91\n",
            "  Downloading awscli-1.18.100-py2.py3-none-any.whl (3.3 MB)\n",
            "Collecting conllu==0.11\n",
            "  Downloading conllu-0.11-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-5.7.tar.gz (58 kB)\n",
            "Collecting matplotlib>=2.2.3\n",
            "  Downloading matplotlib-3.3.0-1-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.18 in /usr/local/lib/python3.6/site-packages (from allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2.24.0)\n",
            "Collecting editdistance\n",
            "  Downloading editdistance-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (178 kB)\n",
            "Requirement already satisfied, skipping upgrade: torch>=0.4.1 in /usr/local/lib/python3.6/site-packages (from allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (1.0.0)\n",
            "Collecting msgpack<0.6.0,>=0.5.6\n",
            "  Downloading msgpack-0.5.6-cp36-cp36m-manylinux1_x86_64.whl (315 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.14.23-py2.py3-none-any.whl (128 kB)\n",
            "Collecting pytest\n",
            "  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/site-packages (from allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (1.15.4)\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading Flask_Cors-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.6/site-packages (from allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2020.1)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "Collecting parsimonious>=0.8.0\n",
            "  Downloading parsimonious-0.8.1.tar.gz (45 kB)\n",
            "Collecting overrides\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "Collecting moto>=1.3.4\n",
            "  Downloading moto-1.3.14-py2.py3-none-any.whl (730 kB)\n",
            "Collecting numpydoc>=0.8.0\n",
            "  Downloading numpydoc-1.1.0-py3-none-any.whl (47 kB)\n",
            "Collecting Jinja2>=2.10.1\n",
            "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
            "Collecting click>=5.1\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "Collecting itsdangerous>=0.24\n",
            "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting Werkzeug>=0.15\n",
            "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "  Downloading thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "Collecting wasabi<1.1.0,>=0.2.0\n",
            "  Downloading wasabi-0.7.1.tar.gz (22 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl (32 kB)\n",
            "Collecting srsly<1.1.0,>=0.0.6\n",
            "  Downloading srsly-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (185 kB)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2 MB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (19 kB)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83 kB)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234 kB)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.4-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting greenlet>=0.4.16; platform_python_implementation == \"CPython\"\n",
            "  Downloading greenlet-0.4.16-cp36-cp36m-manylinux1_x86_64.whl (44 kB)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/site-packages (from gevent>=1.3.6->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (49.2.0.post20200714)\n",
            "Collecting regex\n",
            "  Downloading regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
            "Collecting protobuf>=3.8.0\n",
            "  Downloading protobuf-3.12.2-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/site-packages (from tensorboardX>=1.2->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (1.15.0)\n",
            "Collecting botocore==1.17.23\n",
            "  Downloading botocore-1.17.23-py2.py3-none-any.whl (6.3 MB)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "Collecting PyYAML<5.4,>=3.10; python_version != \"3.4\"\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "Collecting rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"\n",
            "  Downloading rsa-4.5-py2.py3-none-any.whl (36 kB)\n",
            "Collecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/site-packages (from ftfy->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (0.2.5)\n",
            "Collecting pillow>=6.2.0\n",
            "  Downloading Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (88 kB)\n",
            "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2.3->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2.8.1)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests>=2.18->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests>=2.18->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests>=2.18->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (1.25.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests>=2.18->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2020.6.20)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting importlib-metadata>=0.12; python_version < \"3.8\"\n",
            "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting py>=1.5.0\n",
            "  Downloading py-1.9.0-py2.py3-none-any.whl (99 kB)\n",
            "Collecting attrs>=17.4.0\n",
            "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting packaging\n",
            "  Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\n",
            "Collecting more-itertools>=4.0.0\n",
            "  Downloading more_itertools-8.4.0-py3-none-any.whl (43 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
            "Collecting docker>=2.5.1\n",
            "  Downloading docker-4.2.2-py2.py3-none-any.whl (144 kB)\n",
            "Collecting sshpubkeys<4.0,>=3.1.0\n",
            "  Downloading sshpubkeys-3.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting python-jose<4.0.0\n",
            "  Downloading python_jose-3.1.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting aws-xray-sdk!=0.96,>=0.93\n",
            "  Downloading aws_xray_sdk-2.6.0-py2.py3-none-any.whl (94 kB)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied, skipping upgrade: cryptography>=2.3.0 in /usr/local/lib/python3.6/site-packages (from moto>=1.3.4->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2.9.2)\n",
            "Collecting boto>=2.36.0\n",
            "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Collecting jsondiff==1.1.2\n",
            "  Downloading jsondiff-1.1.2.tar.gz (7.8 kB)\n",
            "Collecting cfn-lint>=0.4.0\n",
            "  Downloading cfn_lint-0.34.0-py3-none-any.whl (3.8 MB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting sphinx>=1.6.5\n",
            "  Downloading Sphinx-3.1.2-py3-none-any.whl (2.9 MB)\n",
            "Collecting MarkupSafe>=0.23\n",
            "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
            "Collecting ecdsa>=0.13\n",
            "  Downloading ecdsa-0.15-py2.py3-none-any.whl (100 kB)\n",
            "Collecting future\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/site-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (1.14.0)\n",
            "Collecting jsonschema~=3.0\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "Collecting junit-xml~=1.9\n",
            "  Downloading junit_xml-1.9-py2.py3-none-any.whl (7.1 kB)\n",
            "Collecting importlib-resources~=1.4; python_version < \"3.7\" and python_version != \"3.4\"\n",
            "  Downloading importlib_resources-1.5.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting jsonpatch; python_version != \"3.4\"\n",
            "  Downloading jsonpatch-1.26-py2.py3-none-any.whl (11 kB)\n",
            "Collecting aws-sam-translator>=1.25.0\n",
            "  Downloading aws_sam_translator-1.25.0-py3-none-any.whl (181 kB)\n",
            "Collecting networkx~=2.4; python_version >= \"3.5\"\n",
            "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "Collecting babel>=1.3\n",
            "  Downloading Babel-2.8.0-py2.py3-none-any.whl (8.6 MB)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "Collecting sphinxcontrib-serializinghtml\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.4-py2.py3-none-any.whl (89 kB)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "Collecting alabaster<0.8,>=0.7\n",
            "  Downloading alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "Collecting snowballstemmer>=1.1\n",
            "  Downloading snowballstemmer-2.0.0-py2.py3-none-any.whl (97 kB)\n",
            "Collecting imagesize\n",
            "  Downloading imagesize-1.2.0-py2.py3-none-any.whl (4.8 kB)\n",
            "Requirement already satisfied, skipping upgrade: Pygments>=2.0 in /usr/local/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2.6.1)\n",
            "Collecting sphinxcontrib-htmlhelp\n",
            "  Downloading sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl (96 kB)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3.0->moto>=1.3.4->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (2.20)\n",
            "Collecting pyrsistent>=0.14.0\n",
            "  Downloading pyrsistent-0.16.0.tar.gz (108 kB)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/site-packages (from networkx~=2.4; python_version >= \"3.5\"->cfn-lint>=0.4.0->moto>=1.3.4->allennlp==0.8.3->-r /content/SocialMediaIE/condaenv.fhkc2m3o.requirements.txt (line 1)) (4.4.2)\n",
            "Building wheels for collected packages: word2number, jsonnet, ftfy, parsimonious, overrides, nltk, wasabi, PyYAML, jsondiff, future, wrapt, pyrsistent\n",
            "  Building wheel for word2number (setup.py): started\n",
            "  Building wheel for word2number (setup.py): finished with status 'done'\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5586 sha256=f119e16c95717dcb211f2aec36415598e3ee949896ed552c1f4e78b76b861e27\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/5e/36/8b922f014b64e2a45bac622008bc439281784eb1e09fe5d8d5\n",
            "  Building wheel for jsonnet (setup.py): started\n",
            "  Building wheel for jsonnet (setup.py): finished with status 'done'\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3325695 sha256=f38f7e24def8245b92e70981254541d0fccfb4251daa3652fbc22bac97b70568\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/b4/58/f8bc07c96823d8dcef1a4994e6f7312568bb00e22ee1e532cd\n",
            "  Building wheel for ftfy (setup.py): started\n",
            "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
            "  Created wheel for ftfy: filename=ftfy-5.7-py3-none-any.whl size=44593 sha256=e58ba633c3c03ffc05320c557efcb3592601d3628e943c1daa4158e0e9f91ac0\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/c8/8c/bbd52e77690905d5c933a68005098b6b168e8ea2deff43aa0c\n",
            "  Building wheel for parsimonious (setup.py): started\n",
            "  Building wheel for parsimonious (setup.py): finished with status 'done'\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-py3-none-any.whl size=42709 sha256=a37f62b9a8f624209c0d3ebcaa5e9dd18dfe46f282a7fcaaefe3430b51239f75\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/95/c9/c9f7a3f9dc34ebd851739148bd5b42ab35618ea0808388647c\n",
            "  Building wheel for overrides (setup.py): started\n",
            "  Building wheel for overrides (setup.py): finished with status 'done'\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10173 sha256=2e772d0bc60dffc11852f59dcb0062e0a0ee77b932699a00daa1873e7eaf6e1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/3b/34/ae59fc8d35c37f01099425ab73599e45e9b9b599a7ccc2c45f\n",
            "  Building wheel for nltk (setup.py): started\n",
            "  Building wheel for nltk (setup.py): finished with status 'done'\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434678 sha256=051ac86800c0c1d246f9422265a5f578651608f85839df3f28bcbd008816aa42\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/5e/42/64abaeca668161c3e2cecc24f864a8fc421e3d07a104fc8a51\n",
            "  Building wheel for wasabi (setup.py): started\n",
            "  Building wheel for wasabi (setup.py): finished with status 'done'\n",
            "  Created wheel for wasabi: filename=wasabi-0.7.1-py3-none-any.whl size=20834 sha256=89ec1f67de4aa49e1d4e123f49af48d40951bcbd312d6b7a3f9ff6387ff9d882\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/48/90/cf81833b3dfce6eaf7eab4bd5fdc0e75dbca4418b263f444b8\n",
            "  Building wheel for PyYAML (setup.py): started\n",
            "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=402174 sha256=12febbab5a58cdd13be2478864785f449d6a6cfa50120a6efb7474791610598a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
            "  Building wheel for jsondiff (setup.py): started\n",
            "  Building wheel for jsondiff (setup.py): finished with status 'done'\n",
            "  Created wheel for jsondiff: filename=jsondiff-1.1.2-py3-none-any.whl size=6464 sha256=cf91a1f2fb0c188b69249a442ae76bbbf96740c8f30d60da31b57eccd11c13dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/8b/97/8a62d503d5391bf0a61b47e910deb5d745e8d9d76699ddf986\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=1893d0113e5456bfae271d015407e927c9cae5b7d8e3c101a087e451b8936813\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
            "  Building wheel for wrapt (setup.py): started\n",
            "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69700 sha256=4bf03deedf91a716a1e0b9981b418ba24acbf5f77c0d141a324bf0385400c710\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
            "  Building wheel for pyrsistent (setup.py): started\n",
            "  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
            "  Created wheel for pyrsistent: filename=pyrsistent-0.16.0-cp36-cp36m-linux_x86_64.whl size=114996 sha256=3b22f8ba3065f0b0c267fa24dbb2cad0566a8b8d970c010aa0a4ba91aad189b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/8a/1c/32ab9017418a2c64e4fbaf503c08648bed2f8eb311b869a464\n",
            "Successfully built word2number jsonnet ftfy parsimonious overrides nltk wasabi PyYAML jsondiff future wrapt pyrsistent\n",
            "Installing collected packages: MarkupSafe, Jinja2, click, itsdangerous, Werkzeug, flask, word2number, cymem, preshed, wasabi, blis, srsly, murmurhash, plac, thinc, spacy, sqlparse, jsonnet, flaky, zope.interface, zope.event, greenlet, gevent, regex, jmespath, docutils, botocore, s3transfer, boto3, pytorch-pretrained-bert, protobuf, tensorboardX, responses, PyYAML, pyasn1, rsa, colorama, awscli, conllu, ftfy, pillow, kiwisolver, pyparsing, cycler, matplotlib, h5py, editdistance, msgpack, zipp, importlib-metadata, pluggy, py, attrs, packaging, more-itertools, pytest, flask-cors, unidecode, parsimonious, overrides, joblib, nltk, websocket-client, docker, ecdsa, sshpubkeys, python-jose, future, jsonpickle, wrapt, aws-xray-sdk, mock, boto, jsondiff, pyrsistent, jsonschema, junit-xml, importlib-resources, jsonpointer, jsonpatch, aws-sam-translator, networkx, cfn-lint, xmltodict, moto, babel, sphinxcontrib-applehelp, sphinxcontrib-serializinghtml, sphinxcontrib-devhelp, alabaster, sphinxcontrib-qthelp, snowballstemmer, imagesize, sphinxcontrib-htmlhelp, sphinxcontrib-jsmath, sphinx, numpydoc, allennlp\n",
            "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyYAML-5.3.1 Werkzeug-1.0.1 alabaster-0.7.12 allennlp-0.8.3 attrs-19.3.0 aws-sam-translator-1.25.0 aws-xray-sdk-2.6.0 awscli-1.18.100 babel-2.8.0 blis-0.2.4 boto-2.49.0 boto3-1.14.23 botocore-1.17.23 cfn-lint-0.34.0 click-7.1.2 colorama-0.4.3 conllu-0.11 cycler-0.10.0 cymem-2.0.3 docker-4.2.2 docutils-0.15.2 ecdsa-0.15 editdistance-0.5.3 flaky-3.7.0 flask-1.1.2 flask-cors-3.0.8 ftfy-5.7 future-0.18.2 gevent-20.6.2 greenlet-0.4.16 h5py-2.10.0 imagesize-1.2.0 importlib-metadata-1.7.0 importlib-resources-1.5.0 itsdangerous-1.1.0 jmespath-0.10.0 joblib-0.16.0 jsondiff-1.1.2 jsonnet-0.16.0 jsonpatch-1.26 jsonpickle-1.4.1 jsonpointer-2.0 jsonschema-3.2.0 junit-xml-1.9 kiwisolver-1.2.0 matplotlib-3.3.0 mock-4.0.2 more-itertools-8.4.0 moto-1.3.14 msgpack-0.5.6 murmurhash-1.0.2 networkx-2.4 nltk-3.5 numpydoc-1.1.0 overrides-3.1.0 packaging-20.4 parsimonious-0.8.1 pillow-7.2.0 plac-0.9.6 pluggy-0.13.1 preshed-2.0.1 protobuf-3.12.2 py-1.9.0 pyasn1-0.4.8 pyparsing-2.4.7 pyrsistent-0.16.0 pytest-5.4.3 python-jose-3.1.0 pytorch-pretrained-bert-0.6.2 regex-2020.7.14 responses-0.10.15 rsa-4.5 s3transfer-0.3.3 snowballstemmer-2.0.0 spacy-2.1.9 sphinx-3.1.2 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-1.0.3 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.4 sqlparse-0.3.1 srsly-1.0.2 sshpubkeys-3.1.0 tensorboardX-2.1 thinc-7.0.8 unidecode-1.1.1 wasabi-0.7.1 websocket-client-0.57.0 word2number-1.1 wrapt-1.12.1 xmltodict-0.12.0 zipp-3.1.0 zope.event-4.4 zope.interface-5.1.0\n",
            "\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate base\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SocialMediaIE'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZdxbMhFyqlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881b371c-f66f-4410-8342-5f4ed52ab184"
      },
      "source": [
        "! conda env list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /usr/local\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzmPvkF1qxRu",
        "colab_type": "text"
      },
      "source": [
        "### Setup system path else the dependencies will not load properly "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPJ3AUhqqwBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc44d9f-4ad0-436d-9283-cd7f80fd1ea3"
      },
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "#index_to_insert = min([i for i, v in enumerate(sys.path) if \"dist-packages\" in v])\n",
        "sys.path.insert(0, \"/usr/local/lib/python3.6/site-packages\")\n",
        "sys.path.insert(0, \"./SocialMediaIE/\") # Important to have this first else the package will not load\n",
        "sys.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./SocialMediaIE/',\n",
              " '/usr/local/lib/python3.6/site-packages',\n",
              " '',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9PJf3-Mq73x",
        "colab_type": "text"
      },
      "source": [
        "### Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnzm1a4nt4VU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee0d272-1641-49a4-85ad-a5e29063e9c3"
      },
      "source": [
        "%env SOCIALMEDIAIE_PATH /content/SocialMediaIE/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: SOCIALMEDIAIE_PATH=/content/SocialMediaIE/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klX2G-YsrLRx",
        "colab_type": "text"
      },
      "source": [
        "### Check the SocialMediaIE folder was cloned properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8xubqRDuJQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1790cf3-3333-4ec4-e319-2c7e33e2357b"
      },
      "source": [
        "%%bash \n",
        "echo \"${SOCIALMEDIAIE_PATH}\"\n",
        "ls -ltrh \"${SOCIALMEDIAIE_PATH}/data\"\n",
        "realpath \"${SOCIALMEDIAIE_PATH}\"\n",
        "cd \"${SOCIALMEDIAIE_PATH}\" && ls -ltrh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SocialMediaIE/\n",
            "total 16K\n",
            "-rw-r--r-- 1 root root  11K Jul 19 07:16 databank_api_client_v3.py\n",
            "-rw-r--r-- 1 root root 2.8K Jul 19 07:16 cleanup_model_folders.py\n",
            "/content/SocialMediaIE\n",
            "total 84K\n",
            "-rw-r--r-- 1 root root 2.4K Jul 19 07:16 README.md\n",
            "-rw-r--r-- 1 root root  12K Jul 19 07:16 LICENSE\n",
            "-rw-r--r-- 1 root root 1.7K Jul 19 07:16 TODO.md\n",
            "drwxr-xr-x 9 root root 4.0K Jul 19 07:16 SocialMediaIE\n",
            "drwxr-xr-x 2 root root 4.0K Jul 19 07:16 data\n",
            "-rw-r--r-- 1 root root  338 Jul 19 07:16 environment.yml\n",
            "drwxr-xr-x 3 root root 4.0K Jul 19 07:16 docs\n",
            "drwxr-xr-x 2 root root 4.0K Jul 19 07:16 experiments\n",
            "drwxr-xr-x 4 root root 4.0K Jul 19 07:16 figures\n",
            "drwxr-xr-x 2 root root 4.0K Jul 19 07:16 notebooks\n",
            "drwxr-xr-x 3 root root 4.0K Jul 19 07:16 tests\n",
            "-rw-r--r-- 1 root root  928 Jul 19 07:16 setup.py\n",
            "-rw-r--r-- 1 root root   69 Jul 19 07:16 run_tests.sh\n",
            "-rw-r--r-- 1 root root   69 Jul 19 07:16 run_tests.cmd\n",
            "-rw-r--r-- 1 root root 3.0K Jul 19 07:16 requirements.pinned.txt\n",
            "-rw-r--r-- 1 root root   26 Jul 19 07:16 requirements-dev.txt\n",
            "drwxr-xr-x 4 root root 4.0K Jul 19 07:16 webapp_classification\n",
            "drwxr-xr-x 4 root root 4.0K Jul 19 07:16 webapp\n",
            "drwxr-xr-x 4 root root 4.0K Jul 19 07:16 webapp_classification_tagging\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpXXPrJZ4I5B",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies for Multi Task Learning - SocialMediaIE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdv1FjdnndA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5069e7c2-a5b1-4725-a998-4de794a8a9ee"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsET_z3PnRv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e03c85-cb17-4a2a-c2c4-9ca1d770f1cc"
      },
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm0cUEIVrVNG",
        "colab_type": "text"
      },
      "source": [
        "### Download the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q038Nq6GbVkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "if [ ! -f ic2s2_data.tar.gz ]; then\n",
        "  # Source of data: https://databank.illinois.edu/datasets/IDB-0851257\n",
        "  wget -q https://databank.illinois.edu/datafiles/vodt2/download -O ic2s2_data.tar.gz\n",
        "  cd SocialMediaIE && tar -xzf ../ic2s2_data.tar.gz\n",
        "fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTU6BEjrjXeY",
        "colab_type": "text"
      },
      "source": [
        "# Running models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfl3NS6KjZj9",
        "colab_type": "text"
      },
      "source": [
        "## Multi task tagging\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qDB0cD-jYnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from SocialMediaIE.data.tokenization import get_match_iter, get_match_object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKzYyJj5RVBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e3ea564-2322-4998-c347-989c56e79942"
      },
      "source": [
        "from SocialMediaIE.predictor.model_predictor import run, get_args, PREFIX, get_model_output, output_to_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 336/336 [00:00<00:00, 93286.96B/s]\n",
            "100%|██████████| 374434792/374434792 [00:11<00:00, 31974312.00B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sMAy-ujRBXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "caa0ff17-16a2-4530-8400-f91f30f944ba"
      },
      "source": [
        "SERIALIZATION_DIR = Path(\"./SocialMediaIE/data/models/all_multitask_stacked_l2_0_lr_1e-3_no_neel/\")\n",
        "print(SERIALIZATION_DIR.exists())\n",
        "args = get_args(PREFIX, SERIALIZATION_DIR)\n",
        "args = args._replace(\n",
        "    dataset_paths_file=\"./SocialMediaIE/experiments/all_dataset_paths.json\",\n",
        "    cuda=False # Very important as not running on GPU\n",
        ")\n",
        "args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelArgument(task=['multimodal_ner', 'broad_ner', 'wnut17_ner', 'ritter_ner', 'yodie_ner', 'ritter_chunk', 'ud_pos', 'ark_pos', 'ptb_pos', 'ritter_ccg'], dataset_paths_file='./SocialMediaIE/experiments/all_dataset_paths.json', dataset_path_prefix='/experiments', model_dir='/content/SocialMediaIE/data/models/all_multitask_stacked_l2_0_lr_1e-3_no_neel', clean_model_dir=True, proj_dim=100, hidden_dim=100, encoder_type='bilstm', multi_task_mode='stacked', dropout=0.5, lr=0.001, weight_decay=0.0, batch_size=16, epochs=10, patience=3, cuda=False, test_mode=True, residual_connection=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rlLHAkCkAUr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ad2778ca-6487-4909-a146-888cc6a8b3ee"
      },
      "source": [
        "TASKS, vocab, model, readers, test_iterator = run(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lwoz4j0XvTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4a1eb4d2-68c3-444f-bbdf-b7f456d4ce06"
      },
      "source": [
        "TASKS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Task(tag_namespace='multimodal_ner', task_type=ner, label_encoding=BIO, calculate_span_f1=Trueis_classification=False),\n",
              " Task(tag_namespace='broad_ner', task_type=ner, label_encoding=BIO, calculate_span_f1=Trueis_classification=False),\n",
              " Task(tag_namespace='wnut17_ner', task_type=ner, label_encoding=BIO, calculate_span_f1=Trueis_classification=False),\n",
              " Task(tag_namespace='ritter_ner', task_type=ner, label_encoding=BIO, calculate_span_f1=Trueis_classification=False),\n",
              " Task(tag_namespace='yodie_ner', task_type=ner, label_encoding=BIO, calculate_span_f1=Trueis_classification=False),\n",
              " Task(tag_namespace='ritter_chunk', task_type=chunk, label_encoding=BIO, calculate_span_f1=Trueis_classification=False),\n",
              " Task(tag_namespace='ud_pos', task_type=pos, label_encoding=None, calculate_span_f1=Noneis_classification=False),\n",
              " Task(tag_namespace='ark_pos', task_type=pos, label_encoding=None, calculate_span_f1=Noneis_classification=False),\n",
              " Task(tag_namespace='ptb_pos', task_type=pos, label_encoding=None, calculate_span_f1=Noneis_classification=False),\n",
              " Task(tag_namespace='ritter_ccg', task_type=ccg, label_encoding=BIO, calculate_span_f1=Trueis_classification=False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39TX3sfPYT3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f3ad00cf-04b3-4ba0-f4bc-2fb24110f974"
      },
      "source": [
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocabulary with namespaces:  ritter_chunk, Size: 18 || ark_pos, Size: 25 || ud_pos, Size: 18 || ptb_pos, Size: 46 || broad_ner, Size: 7 || ritter_ner, Size: 21 || multimodal_ner, Size: 9 || tag_namespace, Size: 10 || wnut17_ner, Size: 13 || yodie_ner, Size: 27 || ritter_ccg, Size: 72 || Non Padded Namespaces: {'*ccg', '*ner', '*pos', 'tag_namespace', '*chunk'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auSSN015XvOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37341026-4a27-4354-eb0d-2c5bd8aabad3"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiTaskCRFTagger(\n",
              "  (word_embeddings): BasicTextFieldEmbedder(\n",
              "    (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "      (_elmo): Elmo(\n",
              "        (_elmo_lstm): _ElmoBiLm(\n",
              "          (_token_embedder): _ElmoCharacterEncoder(\n",
              "            (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "            (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "            (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "            (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "            (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "            (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "            (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "            (_highways): Highway(\n",
              "              (_layers): ModuleList(\n",
              "                (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "              )\n",
              "            )\n",
              "            (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          )\n",
              "          (_elmo_lstm): ElmoLstm(\n",
              "            (forward_layer_0): LstmCellWithProjection(\n",
              "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "            )\n",
              "            (backward_layer_0): LstmCellWithProjection(\n",
              "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "            )\n",
              "            (forward_layer_1): LstmCellWithProjection(\n",
              "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "            )\n",
              "            (backward_layer_1): LstmCellWithProjection(\n",
              "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (_dropout): Dropout(p=0.5)\n",
              "        (scalar_mix_0): ScalarMix(\n",
              "          (scalar_parameters): ParameterList(\n",
              "              (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (encoders): ModuleDict(\n",
              "    (ccg): PytorchSeq2SeqWrapper(\n",
              "      (_module): AllenNLPSequential(\n",
              "        (moduleList): ModuleList(\n",
              "          (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5)\n",
              "      )\n",
              "    )\n",
              "    (chunk): PytorchSeq2SeqWrapper(\n",
              "      (_module): AllenNLPSequential(\n",
              "        (moduleList): ModuleList(\n",
              "          (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5)\n",
              "      )\n",
              "    )\n",
              "    (ner): PytorchSeq2SeqWrapper(\n",
              "      (_module): AllenNLPSequential(\n",
              "        (moduleList): ModuleList(\n",
              "          (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          (3): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5)\n",
              "      )\n",
              "    )\n",
              "    (pos): PytorchSeq2SeqWrapper(\n",
              "      (_module): AllenNLPSequential(\n",
              "        (moduleList): ModuleList(\n",
              "          (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.5)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (crftagger): ModuleDict(\n",
              "    (multimodal_ner): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (3): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=9, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (broad_ner): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (3): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=7, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (wnut17_ner): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (3): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=13, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (ritter_ner): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (3): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=21, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (yodie_ner): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (3): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=27, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (ritter_chunk): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=18, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (ud_pos): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=18, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (ark_pos): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=25, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (ptb_pos): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=46, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "    (ritter_ccg): CrfTagger(\n",
              "      (text_field_embedder): BasicTextFieldEmbedder(\n",
              "        (token_embedder_tokens): ElmoTokenEmbedder(\n",
              "          (_elmo): Elmo(\n",
              "            (_elmo_lstm): _ElmoBiLm(\n",
              "              (_token_embedder): _ElmoCharacterEncoder(\n",
              "                (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
              "                (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
              "                (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
              "                (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
              "                (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
              "                (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
              "                (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
              "                (_highways): Highway(\n",
              "                  (_layers): ModuleList(\n",
              "                    (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "                  )\n",
              "                )\n",
              "                (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              )\n",
              "              (_elmo_lstm): ElmoLstm(\n",
              "                (forward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_0): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (forward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "                (backward_layer_1): LstmCellWithProjection(\n",
              "                  (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
              "                  (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
              "                  (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (_dropout): Dropout(p=0.5)\n",
              "            (scalar_mix_0): ScalarMix(\n",
              "              (scalar_parameters): ParameterList(\n",
              "                  (0): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (1): Parameter containing: [torch.FloatTensor of size 1]\n",
              "                  (2): Parameter containing: [torch.FloatTensor of size 1]\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (_projection): Linear(in_features=1024, out_features=100, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (encoder): PytorchSeq2SeqWrapper(\n",
              "        (_module): AllenNLPSequential(\n",
              "          (moduleList): ModuleList(\n",
              "            (0): LSTM(100, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (1): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "            (2): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.5)\n",
              "        )\n",
              "      )\n",
              "      (tag_projection_layer): TimeDistributed(\n",
              "        (_module): Linear(in_features=200, out_features=72, bias=True)\n",
              "      )\n",
              "      (crf): ConditionalRandomField()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erv1j6uKYi6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "e57888b3-d764-436e-9e97-ac00e2e892ce"
      },
      "source": [
        "readers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ark_pos': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d182eb8>,\n",
              " 'broad_ner': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d1826d8>,\n",
              " 'multimodal_ner': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d1825f8>,\n",
              " 'ptb_pos': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3c0d52b0>,\n",
              " 'ritter_ccg': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3c0d3b00>,\n",
              " 'ritter_chunk': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d182d30>,\n",
              " 'ritter_ner': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d182ba8>,\n",
              " 'ud_pos': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d182cf8>,\n",
              " 'wnut17_ner': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d1826a0>,\n",
              " 'yodie_ner': <SocialMediaIE.data.conll_data_reader.ConLLDatasetReader at 0x7f0d3d182b70>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zulyQ2k9kCyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    objects = [get_match_object(match) for match in get_match_iter(text)]\n",
        "    n = len(objects)\n",
        "    cleaned_objects = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        obj[\"no_space\"] = True\n",
        "        if obj[\"type\"] == \"space\":\n",
        "            continue\n",
        "        if i < n-1 and objects[i+1][\"type\"] == \"space\":\n",
        "            obj[\"no_space\"] = False\n",
        "        cleaned_objects.append(obj)\n",
        "    keys = cleaned_objects[0].keys()\n",
        "    final_sequences = {}\n",
        "    for k in keys:\n",
        "        final_sequences[k] = [obj[k] for obj in cleaned_objects]\n",
        "    return final_sequences\n",
        "\n",
        "def predict_df(texts=None):\n",
        "    # Empty cache to ensure larger batch can be loaded for testing\n",
        "    if texts:\n",
        "        data = [tokenize(text) for text in texts]\n",
        "    else:\n",
        "        text = \"Barack Obama went to Paris and never returned to the USA.\"\n",
        "        text1 = \"Stan Lee was a legend who developed Spiderman and the Avengers movie series.\"\n",
        "        text2 = \"I just learned about donald drumph through john oliver. #JohnOliverShow such an awesome show.\"\n",
        "        texts = [text, text1, text2]\n",
        "        data = [tokenize(text) for text in texts]\n",
        "    torch.cuda.empty_cache()\n",
        "    tokens = [obj[\"value\"] for obj in data]\n",
        "    output = list(get_model_output(model, tokens, args, readers, vocab, test_iterator))\n",
        "    idx = 0\n",
        "    def _get_data_values(d):\n",
        "      return {\n",
        "        k: d[k]\n",
        "        for k in d.keys()\n",
        "        if k != \"value\"\n",
        "    }\n",
        "    #df = output_to_df(tokens[idx], output[idx], vocab)\n",
        "    df = pd.concat([\n",
        "                    output_to_df(tokens[i], output[i], vocab).assign(**_get_data_values(d)).assign(data_idx=i)\n",
        "                    for i, d in enumerate(data)\n",
        "          ])\n",
        "\n",
        "    # for k in data[idx].keys():\n",
        "    #     if k != \"value\":\n",
        "    #         df[k] = data[idx][k]\n",
        "    return df\n",
        "\n",
        "\n",
        "def predict_json(texts=None):\n",
        "    # Empty cache to ensure larger batch can be loaded for testing\n",
        "    if texts:\n",
        "      data = [tokenize(text) for text in texts]\n",
        "    else:\n",
        "        text = \"Barack Obama went to Paris and never returned to the USA.\"\n",
        "        text1 = \"Stan Lee was a legend who developed Spiderman and the Avengers movie series.\"\n",
        "        text2 = \"I just learned about donald drumph through john oliver. #JohnOliverShow such an awesome show.\"\n",
        "        texts = [text, text1, text2]\n",
        "        data = [tokenize(text) for text in texts]\n",
        "    torch.cuda.empty_cache()\n",
        "    tokens = [obj[\"value\"] for obj in data]\n",
        "    output = list(get_model_output(model, tokens, args, readers, vocab, test_iterator))\n",
        "    # idx = 0\n",
        "    # df = output_to_df(tokens[idx], output[idx], vocab)\n",
        "    # for k in data[idx].keys():\n",
        "    #     if k != \"value\":\n",
        "    #         df[k] = data[idx][k]\n",
        "    # #df = df.set_index(\"tokens\")\n",
        "    # output_json = df.to_json(orient='table')\n",
        "    # output_json = json.loads(output_json)\n",
        "    # output_json = dict(tagging=output_json)\n",
        "    def _get_data_values(d):\n",
        "      return {\n",
        "        k: d[k]\n",
        "        for k in d.keys()\n",
        "        if k != \"value\"\n",
        "    }\n",
        "    #df = output_to_df(tokens[idx], output[idx], vocab)\n",
        "    output = [\n",
        "                    output_to_df(tokens[i], output[i], vocab).assign(**_get_data_values(d)).assign(data_idx=i)\n",
        "                    for i, d in enumerate(data)\n",
        "          ]\n",
        "    output = [\n",
        "            dict(tagging=json.loads(df_t.to_json(orient='table')))\n",
        "            for df_t in output\n",
        "    ]\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u23UGKSWv6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3cf1c3a2-9eac-47f6-d304-5f395a865baa"
      },
      "source": [
        "output_json = predict_json()\n",
        "json.dumps(output_json[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'{\"tagging\": {\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"integer\"}, {\"name\": \"tokens\", \"type\": \"string\"}, {\"name\": \"multimodal_ner\", \"type\": \"string\"}, {\"name\": \"broad_ner\", \"type\": \"string\"}, {\"name\": \"wnut17_ner\", \"type\": \"string\"}, {\"name\": \"ritter_ner\", \"type\": \"string\"}, {\"name\": \"yodie_ner\", \"type\": \"string\"}, {\"name\": \"ritter_chunk\", \"type\": \"string\"}, {\"name\": \"ud_pos\", \"type\": \"string\"}, {\"name\": \"ark_pos\", \"type\": \"string\"}, {\"name\": \"ptb_pos\", \"type\": \"string\"}, {\"name\": \"ritter_ccg\", \"type\": \"string\"}, {\"name\": \"type\", \"type\": \"string\"}, {\"name\": \"span\", \"type\": \"string\"}, {\"name\": \"is_hashtag\", \"type\": \"boolean\"}, {\"name\": \"is_mention\", \"type\": \"boolean\"}, {\"name\": \"is_url\", \"type\": \"boolean\"}, {\"name\": \"is_emoji\", \"type\": \"boolean\"}, {\"name\": \"is_emoticon\", \"type\": \"boolean\"}, {\"name\": \"is_symbol\", \"type\": \"boolean\"}, {\"name\": \"no_space\", \"type\": \"boolean\"}, {\"name\": \"data_idx\", \"type\": \"integer\"}], \"primaryKey\": [\"index\"], \"pandas_version\": \"0.20.0\"}, \"data\": [{\"index\": 0, \"tokens\": \"Barack\", \"multimodal_ner\": \"B-PER\", \"broad_ner\": \"B-PER\", \"wnut17_ner\": \"B-PERSON\", \"ritter_ner\": \"B-PERSON\", \"yodie_ner\": \"B-PERSON\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.PERSON\", \"type\": \"token\", \"span\": [0, 6], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 1, \"tokens\": \"Obama\", \"multimodal_ner\": \"I-PER\", \"broad_ner\": \"I-PER\", \"wnut17_ner\": \"I-PERSON\", \"ritter_ner\": \"I-PERSON\", \"yodie_ner\": \"I-PERSON\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.PERSON\", \"type\": \"token\", \"span\": [7, 12], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 2, \"tokens\": \"went\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VBD\", \"ritter_ccg\": \"B-VERB.MOTION\", \"type\": \"token\", \"span\": [13, 17], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 3, \"tokens\": \"to\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"TO\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [18, 20], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 4, \"tokens\": \"Paris\", \"multimodal_ner\": \"B-LOC\", \"broad_ner\": \"B-LOC\", \"wnut17_ner\": \"B-LOCATION\", \"ritter_ner\": \"B-GEO-LOC\", \"yodie_ner\": \"B-LOCATION\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.LOCATION\", \"type\": \"token\", \"span\": [21, 26], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 5, \"tokens\": \"and\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"O\", \"ud_pos\": \"CCONJ\", \"ark_pos\": \"&\", \"ptb_pos\": \"CC\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [27, 30], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 6, \"tokens\": \"never\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-ADVP\", \"ud_pos\": \"ADV\", \"ark_pos\": \"R\", \"ptb_pos\": \"RB\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [31, 36], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 7, \"tokens\": \"returned\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VBN\", \"ritter_ccg\": \"B-VERB.MOTION\", \"type\": \"token\", \"span\": [37, 45], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 8, \"tokens\": \"to\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"TO\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [46, 48], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 9, \"tokens\": \"the\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"B-LOCATION\", \"ritter_ner\": \"B-FACILITY\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [49, 52], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 10, \"tokens\": \"USA\", \"multimodal_ner\": \"B-LOC\", \"broad_ner\": \"B-LOC\", \"wnut17_ner\": \"I-LOCATION\", \"ritter_ner\": \"I-FACILITY\", \"yodie_ner\": \"B-GEO-LOC\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.LOCATION\", \"type\": \"token\", \"span\": [53, 56], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 11, \"tokens\": \".\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"O\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \"PUNCT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [56, 57], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": true, \"data_idx\": 0}]}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4e4sPmSBKZ9",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the output:\n",
        "\n",
        "You can copy the JSON output of the above cell and paste it at (and click Visualize): https://codepen.io/napsternxg/full/YzwRqEb to see a pretty representation of the output as shown in the presentation. \n",
        "\n",
        "If you hover over the output of the above cell, Colab will show you how to copy it to clipboard. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVXBqHILkPab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = predict_df()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29iu9MxWaTA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "829b3822-d828-4d8f-9b46-73f3de6c09b6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barack</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 6)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Obama</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(7, 12)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBD</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(13, 17)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(18, 20)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Paris</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(21, 26)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0  Barack          B-PER     B-PER  ...     False    False        0\n",
              "1   Obama          I-PER     I-PER  ...     False    False        0\n",
              "2    went              O         O  ...     False    False        0\n",
              "3      to              O         O  ...     False    False        0\n",
              "4   Paris          B-LOC     B-LOC  ...     False    False        0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znc9eWA6ah11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "5e94723d-8b11-4a04-da3e-9225dd852b7f"
      },
      "source": [
        "df[df.data_idx==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barack</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 6)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Obama</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(7, 12)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBD</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(13, 17)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(18, 20)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Paris</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(21, 26)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>&amp;</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(27, 30)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>never</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ADVP</td>\n",
              "      <td>ADV</td>\n",
              "      <td>R</td>\n",
              "      <td>RB</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(31, 36)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>returned</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBN</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(37, 45)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(46, 48)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-FACILITY</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>DET</td>\n",
              "      <td>D</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(49, 52)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>USA</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOCATION</td>\n",
              "      <td>I-FACILITY</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(53, 56)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(56, 57)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0     Barack          B-PER     B-PER  ...     False    False        0\n",
              "1      Obama          I-PER     I-PER  ...     False    False        0\n",
              "2       went              O         O  ...     False    False        0\n",
              "3         to              O         O  ...     False    False        0\n",
              "4      Paris          B-LOC     B-LOC  ...     False    False        0\n",
              "5        and              O         O  ...     False    False        0\n",
              "6      never              O         O  ...     False    False        0\n",
              "7   returned              O         O  ...     False    False        0\n",
              "8         to              O         O  ...     False    False        0\n",
              "9        the              O         O  ...     False    False        0\n",
              "10       USA          B-LOC     B-LOC  ...     False     True        0\n",
              "11         .              O         O  ...      True     True        0\n",
              "\n",
              "[12 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7PCgTHuam2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "5a8f4188-a1dd-4593-c78e-a4a657e9bfb1"
      },
      "source": [
        "df.loc[df.data_idx==0, [\"tokens\", \"multimodal_ner\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barack</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Obama</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Paris</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>never</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>returned</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>USA</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tokens multimodal_ner\n",
              "0     Barack          B-PER\n",
              "1      Obama          I-PER\n",
              "2       went              O\n",
              "3         to              O\n",
              "4      Paris          B-LOC\n",
              "5        and              O\n",
              "6      never              O\n",
              "7   returned              O\n",
              "8         to              O\n",
              "9        the              O\n",
              "10       USA          B-LOC\n",
              "11         .              O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O561LtLubEVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_tag(tag):\n",
        "    return tuple(tag.split(\"-\", 1)) if tag != \"O\" else (tag, None) \n",
        "    \n",
        "def extract_entities(tags):\n",
        "    tags = list(tags)\n",
        "    curr_entity = []\n",
        "    entities = []\n",
        "    for i,tag in enumerate(tags + [\"O\"]):\n",
        "        # Add dummy tag in end to ensure the last entity is added to entities\n",
        "        boundary, label = split_tag(tag)\n",
        "        if curr_entity:\n",
        "            # Exit entity\n",
        "            if boundary in {\"B\", \"O\"} or label != curr_entity[-1][1]:\n",
        "                start = i - len(curr_entity)\n",
        "                end = i\n",
        "                entity_label = curr_entity[-1][1]\n",
        "                entities.append((entity_label, start, end))\n",
        "                curr_entity = []\n",
        "            elif boundary == \"I\":\n",
        "                curr_entity.append((boundary, label))\n",
        "        if boundary == \"B\":\n",
        "            # Enter or inside entity\n",
        "            assert not curr_entity, f\"Entity should be empty. Found: {curr_entity}\"\n",
        "            curr_entity.append((boundary, label))\n",
        "    return entities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV1rfJRDbdp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "de3f3e9a-d655-422e-870c-1fee224d2c6a"
      },
      "source": [
        "df_t = df.loc[df.data_idx==0]\n",
        "df_t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barack</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 6)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Obama</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(7, 12)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBD</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(13, 17)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(18, 20)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Paris</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(21, 26)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>&amp;</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(27, 30)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>never</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ADVP</td>\n",
              "      <td>ADV</td>\n",
              "      <td>R</td>\n",
              "      <td>RB</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(31, 36)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>returned</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBN</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(37, 45)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(46, 48)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-FACILITY</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>DET</td>\n",
              "      <td>D</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(49, 52)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>USA</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOCATION</td>\n",
              "      <td>I-FACILITY</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(53, 56)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(56, 57)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0     Barack          B-PER     B-PER  ...     False    False        0\n",
              "1      Obama          I-PER     I-PER  ...     False    False        0\n",
              "2       went              O         O  ...     False    False        0\n",
              "3         to              O         O  ...     False    False        0\n",
              "4      Paris          B-LOC     B-LOC  ...     False    False        0\n",
              "5        and              O         O  ...     False    False        0\n",
              "6      never              O         O  ...     False    False        0\n",
              "7   returned              O         O  ...     False    False        0\n",
              "8         to              O         O  ...     False    False        0\n",
              "9        the              O         O  ...     False    False        0\n",
              "10       USA          B-LOC     B-LOC  ...     False     True        0\n",
              "11         .              O         O  ...      True     True        0\n",
              "\n",
              "[12 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VePVG0lYbGdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entities = extract_entities(df_t[\"multimodal_ner\"])\n",
        "tokens = list(df_t[\"tokens\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o38sGYCgbqjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "127de94e-8064-47ec-8990-b5101733e48e"
      },
      "source": [
        "for label, start, end in entities:\n",
        "  print(tokens[start:end], label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Barack', 'Obama'] PER\n",
            "['Paris'] LOC\n",
            "['USA'] LOC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLUhp8s0bRek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "7b72efb9-a864-4140-e4e0-ba8b7acea78f"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tokens', 'multimodal_ner', 'broad_ner', 'wnut17_ner', 'ritter_ner',\n",
              "       'yodie_ner', 'ritter_chunk', 'ud_pos', 'ark_pos', 'ptb_pos',\n",
              "       'ritter_ccg', 'type', 'span', 'is_hashtag', 'is_mention', 'is_url',\n",
              "       'is_emoji', 'is_emoticon', 'is_symbol', 'no_space', 'data_idx'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhljzwDCb9_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_entity_info(bio_labels, tokens, text=None, spans=None):\n",
        "  entities_info = extract_entities(bio_labels)\n",
        "  entities = []\n",
        "  for label, start, end in entities_info:\n",
        "    entity_phrase = None\n",
        "    if text and spans:\n",
        "      start_char_idx = spans[start][0]\n",
        "      end_char_idx = spans[end-1][1]\n",
        "      entity_phrase = text[start_char_idx:end_char_idx]\n",
        "    entities.append(dict(\n",
        "        tokens=tokens[start:end], \n",
        "        label=label, \n",
        "        start=start, \n",
        "        end=end, \n",
        "        entity_phrase=entity_phrase))\n",
        "  return entities\n",
        "\n",
        "\n",
        "def get_df_entities(df, text=None):\n",
        "  span_columns = [\n",
        "    c for c in df.columns if c.endswith((\"_ner\", \"_chunk\", \"_ccg\"))\n",
        "  ]\n",
        "  tokens = list(df[\"tokens\"])\n",
        "  spans = list(df[\"span\"])\n",
        "  task_entities = {c: [] for c in span_columns}\n",
        "  for c in span_columns:\n",
        "    bio_labels = df[c]\n",
        "    task_entities[c] = get_entity_info(bio_labels, tokens, text=text, spans=spans)\n",
        "  return task_entities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnFLl6f10rmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "71c1f4e8-b2a9-4bb1-8c2b-4bee7285e2a9"
      },
      "source": [
        "text = \"\"\"Ryan Gosling and Chris Evans will star in the Russo Bros' 'The Gray Man' for Netflix\n",
        "\n",
        "The film has a $200M+ budget and the goal is to launch a James Bond-level franchise\n",
        "\n",
        "'For those who were fans of The Winter Soldier this is us moving into that territory in a real-world setting'\"\"\"\n",
        "\n",
        "df = predict_df([text])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ryan</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 4)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gosling</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(5, 12)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>&amp;</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(13, 16)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chris</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(17, 22)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Evans</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(23, 28)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>real</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>A</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(261, 265)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(265, 266)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>world</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>N</td>\n",
              "      <td>NN</td>\n",
              "      <td>B-NOUN.ACT</td>\n",
              "      <td>token</td>\n",
              "      <td>(266, 271)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>setting</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>N</td>\n",
              "      <td>NN</td>\n",
              "      <td>I-NOUN.ACT</td>\n",
              "      <td>token</td>\n",
              "      <td>(272, 279)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>'</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>''</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(279, 280)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0      Ryan          B-PER     B-PER  ...     False    False        0\n",
              "1   Gosling          I-PER     I-PER  ...     False    False        0\n",
              "2       and              O         O  ...     False    False        0\n",
              "3     Chris          B-PER     B-PER  ...     False    False        0\n",
              "4     Evans          I-PER     I-PER  ...     False    False        0\n",
              "..      ...            ...       ...  ...       ...      ...      ...\n",
              "59     real              O         O  ...     False     True        0\n",
              "60        -              O         O  ...      True     True        0\n",
              "61    world              O         O  ...     False    False        0\n",
              "62  setting              O         O  ...     False     True        0\n",
              "63        '              O         O  ...      True     True        0\n",
              "\n",
              "[64 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVxjDVU_z8VZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1dc799d-2603-4e08-89a1-cb5e9f09b5d3"
      },
      "source": [
        "task_entities = get_df_entities(df, text=text)\n",
        "for task, entities in task_entities.items():\n",
        "  print(task)\n",
        "  for entity in entities:\n",
        "    print(entity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multimodal_ner\n",
            "{'tokens': ['Ryan', 'Gosling'], 'label': 'PER', 'start': 0, 'end': 2, 'entity_phrase': 'Ryan Gosling'}\n",
            "{'tokens': ['Chris', 'Evans'], 'label': 'PER', 'start': 3, 'end': 5, 'entity_phrase': 'Chris Evans'}\n",
            "{'tokens': ['Russo', 'Bros'], 'label': 'ORG', 'start': 9, 'end': 11, 'entity_phrase': 'Russo Bros'}\n",
            "{'tokens': ['The', 'Gray', 'Man'], 'label': 'MISC', 'start': 13, 'end': 16, 'entity_phrase': 'The Gray Man'}\n",
            "{'tokens': ['Netflix'], 'label': 'ORG', 'start': 18, 'end': 19, 'entity_phrase': 'Netflix'}\n",
            "{'tokens': ['James', 'Bond'], 'label': 'PER', 'start': 35, 'end': 37, 'entity_phrase': 'James Bond'}\n",
            "{'tokens': ['The', 'Winter', 'Soldier'], 'label': 'MISC', 'start': 47, 'end': 50, 'entity_phrase': 'The Winter Soldier'}\n",
            "broad_ner\n",
            "{'tokens': ['Ryan', 'Gosling'], 'label': 'PER', 'start': 0, 'end': 2, 'entity_phrase': 'Ryan Gosling'}\n",
            "{'tokens': ['Chris', 'Evans'], 'label': 'PER', 'start': 3, 'end': 5, 'entity_phrase': 'Chris Evans'}\n",
            "{'tokens': ['Russo', 'Bros'], 'label': 'PER', 'start': 9, 'end': 11, 'entity_phrase': 'Russo Bros'}\n",
            "{'tokens': ['Netflix'], 'label': 'ORG', 'start': 18, 'end': 19, 'entity_phrase': 'Netflix'}\n",
            "{'tokens': ['James', 'Bond'], 'label': 'PER', 'start': 35, 'end': 37, 'entity_phrase': 'James Bond'}\n",
            "wnut17_ner\n",
            "{'tokens': ['Ryan', 'Gosling'], 'label': 'PERSON', 'start': 0, 'end': 2, 'entity_phrase': 'Ryan Gosling'}\n",
            "{'tokens': ['Chris', 'Evans'], 'label': 'PERSON', 'start': 3, 'end': 5, 'entity_phrase': 'Chris Evans'}\n",
            "{'tokens': ['Russo', 'Bros'], 'label': 'GROUP', 'start': 9, 'end': 11, 'entity_phrase': 'Russo Bros'}\n",
            "{'tokens': ['The', 'Gray', 'Man'], 'label': 'CREATIVE-WORK', 'start': 13, 'end': 16, 'entity_phrase': 'The Gray Man'}\n",
            "{'tokens': ['Netflix'], 'label': 'CORPORATION', 'start': 18, 'end': 19, 'entity_phrase': 'Netflix'}\n",
            "{'tokens': ['James', 'Bond'], 'label': 'PERSON', 'start': 35, 'end': 37, 'entity_phrase': 'James Bond'}\n",
            "{'tokens': ['The', 'Winter', 'Soldier'], 'label': 'CREATIVE-WORK', 'start': 47, 'end': 50, 'entity_phrase': 'The Winter Soldier'}\n",
            "ritter_ner\n",
            "{'tokens': ['Ryan', 'Gosling'], 'label': 'PERSON', 'start': 0, 'end': 2, 'entity_phrase': 'Ryan Gosling'}\n",
            "{'tokens': ['Chris', 'Evans'], 'label': 'PERSON', 'start': 3, 'end': 5, 'entity_phrase': 'Chris Evans'}\n",
            "{'tokens': ['Russo', 'Bros'], 'label': 'PERSON', 'start': 9, 'end': 11, 'entity_phrase': 'Russo Bros'}\n",
            "{'tokens': ['The', 'Gray', 'Man'], 'label': 'OTHER', 'start': 13, 'end': 16, 'entity_phrase': 'The Gray Man'}\n",
            "{'tokens': ['Netflix'], 'label': 'COMPANY', 'start': 18, 'end': 19, 'entity_phrase': 'Netflix'}\n",
            "{'tokens': ['James', 'Bond'], 'label': 'PERSON', 'start': 35, 'end': 37, 'entity_phrase': 'James Bond'}\n",
            "{'tokens': ['The', 'Winter', 'Soldier'], 'label': 'TVSHOW', 'start': 47, 'end': 50, 'entity_phrase': 'The Winter Soldier'}\n",
            "yodie_ner\n",
            "{'tokens': ['Ryan', 'Gosling'], 'label': 'PERSON', 'start': 0, 'end': 2, 'entity_phrase': 'Ryan Gosling'}\n",
            "{'tokens': ['Chris', 'Evans'], 'label': 'PERSON', 'start': 3, 'end': 5, 'entity_phrase': 'Chris Evans'}\n",
            "{'tokens': ['Russo', 'Bros'], 'label': 'SPORTSTEAM', 'start': 9, 'end': 11, 'entity_phrase': 'Russo Bros'}\n",
            "{'tokens': ['Netflix'], 'label': 'ORGANIZATION', 'start': 18, 'end': 19, 'entity_phrase': 'Netflix'}\n",
            "{'tokens': ['James', 'Bond'], 'label': 'PERSON', 'start': 35, 'end': 37, 'entity_phrase': 'James Bond'}\n",
            "ritter_chunk\n",
            "{'tokens': ['Ryan', 'Gosling', 'and', 'Chris', 'Evans'], 'label': 'NP', 'start': 0, 'end': 5, 'entity_phrase': 'Ryan Gosling and Chris Evans'}\n",
            "{'tokens': ['will', 'star'], 'label': 'VP', 'start': 5, 'end': 7, 'entity_phrase': 'will star'}\n",
            "{'tokens': ['in'], 'label': 'PP', 'start': 7, 'end': 8, 'entity_phrase': 'in'}\n",
            "{'tokens': ['the', 'Russo', 'Bros', \"'\", \"'\", 'The', 'Gray', 'Man', \"'\"], 'label': 'NP', 'start': 8, 'end': 17, 'entity_phrase': \"the Russo Bros' 'The Gray Man'\"}\n",
            "{'tokens': ['for'], 'label': 'PP', 'start': 17, 'end': 18, 'entity_phrase': 'for'}\n",
            "{'tokens': ['Netflix'], 'label': 'NP', 'start': 18, 'end': 19, 'entity_phrase': 'Netflix'}\n",
            "{'tokens': ['The', 'film'], 'label': 'NP', 'start': 19, 'end': 21, 'entity_phrase': 'The film'}\n",
            "{'tokens': ['has'], 'label': 'VP', 'start': 21, 'end': 22, 'entity_phrase': 'has'}\n",
            "{'tokens': ['a', '$', '200', 'M', '+', 'budget'], 'label': 'NP', 'start': 22, 'end': 28, 'entity_phrase': 'a $200M+ budget'}\n",
            "{'tokens': ['the', 'goal'], 'label': 'NP', 'start': 29, 'end': 31, 'entity_phrase': 'the goal'}\n",
            "{'tokens': ['is', 'to', 'launch'], 'label': 'VP', 'start': 31, 'end': 34, 'entity_phrase': 'is to launch'}\n",
            "{'tokens': ['a', 'James', 'Bond'], 'label': 'NP', 'start': 34, 'end': 37, 'entity_phrase': 'a James Bond'}\n",
            "{'tokens': ['level', 'franchise'], 'label': 'NP', 'start': 38, 'end': 40, 'entity_phrase': 'level franchise'}\n",
            "{'tokens': ['For'], 'label': 'PP', 'start': 41, 'end': 42, 'entity_phrase': 'For'}\n",
            "{'tokens': ['those'], 'label': 'NP', 'start': 42, 'end': 43, 'entity_phrase': 'those'}\n",
            "{'tokens': ['who'], 'label': 'NP', 'start': 43, 'end': 44, 'entity_phrase': 'who'}\n",
            "{'tokens': ['were'], 'label': 'VP', 'start': 44, 'end': 45, 'entity_phrase': 'were'}\n",
            "{'tokens': ['fans'], 'label': 'NP', 'start': 45, 'end': 46, 'entity_phrase': 'fans'}\n",
            "{'tokens': ['of'], 'label': 'PP', 'start': 46, 'end': 47, 'entity_phrase': 'of'}\n",
            "{'tokens': ['The', 'Winter', 'Soldier'], 'label': 'NP', 'start': 47, 'end': 50, 'entity_phrase': 'The Winter Soldier'}\n",
            "{'tokens': ['this'], 'label': 'NP', 'start': 50, 'end': 51, 'entity_phrase': 'this'}\n",
            "{'tokens': ['is'], 'label': 'VP', 'start': 51, 'end': 52, 'entity_phrase': 'is'}\n",
            "{'tokens': ['us'], 'label': 'NP', 'start': 52, 'end': 53, 'entity_phrase': 'us'}\n",
            "{'tokens': ['moving'], 'label': 'VP', 'start': 53, 'end': 54, 'entity_phrase': 'moving'}\n",
            "{'tokens': ['into'], 'label': 'PP', 'start': 54, 'end': 55, 'entity_phrase': 'into'}\n",
            "{'tokens': ['that', 'territory'], 'label': 'NP', 'start': 55, 'end': 57, 'entity_phrase': 'that territory'}\n",
            "{'tokens': ['in'], 'label': 'PP', 'start': 57, 'end': 58, 'entity_phrase': 'in'}\n",
            "{'tokens': ['a', 'real', '-', 'world', 'setting'], 'label': 'NP', 'start': 58, 'end': 63, 'entity_phrase': 'a real-world setting'}\n",
            "ritter_ccg\n",
            "{'tokens': ['Ryan', 'Gosling'], 'label': 'NOUN.PERSON', 'start': 0, 'end': 2, 'entity_phrase': 'Ryan Gosling'}\n",
            "{'tokens': ['Chris', 'Evans'], 'label': 'NOUN.PERSON', 'start': 3, 'end': 5, 'entity_phrase': 'Chris Evans'}\n",
            "{'tokens': ['star'], 'label': 'VERB.COMMUNICATION', 'start': 6, 'end': 7, 'entity_phrase': 'star'}\n",
            "{'tokens': ['Russo', 'Bros'], 'label': 'NOUN.GROUP', 'start': 9, 'end': 11, 'entity_phrase': 'Russo Bros'}\n",
            "{'tokens': ['The', 'Gray', 'Man'], 'label': 'NOUN.COMMUNICATION', 'start': 13, 'end': 16, 'entity_phrase': 'The Gray Man'}\n",
            "{'tokens': ['Netflix'], 'label': 'NOUN.COMMUNICATION', 'start': 18, 'end': 19, 'entity_phrase': 'Netflix'}\n",
            "{'tokens': ['film'], 'label': 'NOUN.COMMUNICATION', 'start': 20, 'end': 21, 'entity_phrase': 'film'}\n",
            "{'tokens': ['has'], 'label': 'VERB.STATIVE', 'start': 21, 'end': 22, 'entity_phrase': 'has'}\n",
            "{'tokens': ['budget'], 'label': 'NOUN.POSSESSION', 'start': 27, 'end': 28, 'entity_phrase': 'budget'}\n",
            "{'tokens': ['goal'], 'label': 'NOUN.ATTRIBUTE', 'start': 30, 'end': 31, 'entity_phrase': 'goal'}\n",
            "{'tokens': ['is'], 'label': 'VERB.STATIVE', 'start': 31, 'end': 32, 'entity_phrase': 'is'}\n",
            "{'tokens': ['launch'], 'label': 'VERB.PERCEPTION', 'start': 33, 'end': 34, 'entity_phrase': 'launch'}\n",
            "{'tokens': ['James', 'Bond'], 'label': 'NOUN.ARTIFACT', 'start': 35, 'end': 37, 'entity_phrase': 'James Bond'}\n",
            "{'tokens': ['level', 'franchise'], 'label': 'NOUN.ARTIFACT', 'start': 38, 'end': 40, 'entity_phrase': 'level franchise'}\n",
            "{'tokens': ['were'], 'label': 'VERB.STATIVE', 'start': 44, 'end': 45, 'entity_phrase': 'were'}\n",
            "{'tokens': ['fans'], 'label': 'NOUN.GROUP', 'start': 45, 'end': 46, 'entity_phrase': 'fans'}\n",
            "{'tokens': ['The', 'Winter', 'Soldier'], 'label': 'NOUN.COMMUNICATION', 'start': 47, 'end': 50, 'entity_phrase': 'The Winter Soldier'}\n",
            "{'tokens': ['is'], 'label': 'VERB.STATIVE', 'start': 51, 'end': 52, 'entity_phrase': 'is'}\n",
            "{'tokens': ['moving'], 'label': 'VERB.CHANGE', 'start': 53, 'end': 54, 'entity_phrase': 'moving'}\n",
            "{'tokens': ['territory'], 'label': 'NOUN.LOCATION', 'start': 56, 'end': 57, 'entity_phrase': 'territory'}\n",
            "{'tokens': ['world', 'setting'], 'label': 'NOUN.ACT', 'start': 61, 'end': 63, 'entity_phrase': 'world setting'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lq_MQxwckbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4346745e-333a-421b-ee69-d27a2bfa62ce"
      },
      "source": [
        "text = \"\"\"Ryan Gosling and Chris Evans will star in the Russo Bros' 'The Gray Man' for Netflix\n",
        "\n",
        "The film has a $200M+ budget and the goal is to launch a James Bond-level franchise\n",
        "\n",
        "'For those who were fans of The Winter Soldier this is us moving into that territory in a real-world setting'\"\"\"\n",
        "json.dumps(predict_json([text])[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'{\"tagging\": {\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"integer\"}, {\"name\": \"tokens\", \"type\": \"string\"}, {\"name\": \"multimodal_ner\", \"type\": \"string\"}, {\"name\": \"broad_ner\", \"type\": \"string\"}, {\"name\": \"wnut17_ner\", \"type\": \"string\"}, {\"name\": \"ritter_ner\", \"type\": \"string\"}, {\"name\": \"yodie_ner\", \"type\": \"string\"}, {\"name\": \"ritter_chunk\", \"type\": \"string\"}, {\"name\": \"ud_pos\", \"type\": \"string\"}, {\"name\": \"ark_pos\", \"type\": \"string\"}, {\"name\": \"ptb_pos\", \"type\": \"string\"}, {\"name\": \"ritter_ccg\", \"type\": \"string\"}, {\"name\": \"type\", \"type\": \"string\"}, {\"name\": \"span\", \"type\": \"string\"}, {\"name\": \"is_hashtag\", \"type\": \"boolean\"}, {\"name\": \"is_mention\", \"type\": \"boolean\"}, {\"name\": \"is_url\", \"type\": \"boolean\"}, {\"name\": \"is_emoji\", \"type\": \"boolean\"}, {\"name\": \"is_emoticon\", \"type\": \"boolean\"}, {\"name\": \"is_symbol\", \"type\": \"boolean\"}, {\"name\": \"no_space\", \"type\": \"boolean\"}, {\"name\": \"data_idx\", \"type\": \"integer\"}], \"primaryKey\": [\"index\"], \"pandas_version\": \"0.20.0\"}, \"data\": [{\"index\": 0, \"tokens\": \"Ryan\", \"multimodal_ner\": \"B-PER\", \"broad_ner\": \"B-PER\", \"wnut17_ner\": \"B-PERSON\", \"ritter_ner\": \"B-PERSON\", \"yodie_ner\": \"B-PERSON\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.PERSON\", \"type\": \"token\", \"span\": [0, 4], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 1, \"tokens\": \"Gosling\", \"multimodal_ner\": \"I-PER\", \"broad_ner\": \"I-PER\", \"wnut17_ner\": \"I-PERSON\", \"ritter_ner\": \"I-PERSON\", \"yodie_ner\": \"I-PERSON\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.PERSON\", \"type\": \"token\", \"span\": [5, 12], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 2, \"tokens\": \"and\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"CCONJ\", \"ark_pos\": \"&\", \"ptb_pos\": \"CC\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [13, 16], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 3, \"tokens\": \"Chris\", \"multimodal_ner\": \"B-PER\", \"broad_ner\": \"B-PER\", \"wnut17_ner\": \"B-PERSON\", \"ritter_ner\": \"B-PERSON\", \"yodie_ner\": \"B-PERSON\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.PERSON\", \"type\": \"token\", \"span\": [17, 22], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 4, \"tokens\": \"Evans\", \"multimodal_ner\": \"I-PER\", \"broad_ner\": \"I-PER\", \"wnut17_ner\": \"I-PERSON\", \"ritter_ner\": \"I-PERSON\", \"yodie_ner\": \"I-PERSON\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.PERSON\", \"type\": \"token\", \"span\": [23, 28], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 5, \"tokens\": \"will\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"AUX\", \"ark_pos\": \"V\", \"ptb_pos\": \"MD\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [29, 33], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 6, \"tokens\": \"star\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"B-VERB.COMMUNICATION\", \"type\": \"token\", \"span\": [34, 38], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 7, \"tokens\": \"in\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"IN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [39, 41], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 8, \"tokens\": \"the\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [42, 45], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 9, \"tokens\": \"Russo\", \"multimodal_ner\": \"B-ORG\", \"broad_ner\": \"B-PER\", \"wnut17_ner\": \"B-GROUP\", \"ritter_ner\": \"B-PERSON\", \"yodie_ner\": \"B-SPORTSTEAM\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.GROUP\", \"type\": \"token\", \"span\": [46, 51], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 10, \"tokens\": \"Bros\", \"multimodal_ner\": \"I-ORG\", \"broad_ner\": \"I-PER\", \"wnut17_ner\": \"I-GROUP\", \"ritter_ner\": \"I-PERSON\", \"yodie_ner\": \"I-SPORTSTEAM\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.GROUP\", \"type\": \"token\", \"span\": [52, 56], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 11, \"tokens\": \"\\'\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \"\\'\\'\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [56, 57], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": false, \"data_idx\": 0}, {\"index\": 12, \"tokens\": \"\\'\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \"\\'\\'\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [58, 59], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": true, \"data_idx\": 0}, {\"index\": 13, \"tokens\": \"The\", \"multimodal_ner\": \"B-MISC\", \"broad_ner\": \"O\", \"wnut17_ner\": \"B-CREATIVE-WORK\", \"ritter_ner\": \"B-OTHER\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"D\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [59, 62], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 14, \"tokens\": \"Gray\", \"multimodal_ner\": \"I-MISC\", \"broad_ner\": \"O\", \"wnut17_ner\": \"I-CREATIVE-WORK\", \"ritter_ner\": \"I-OTHER\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [63, 67], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 15, \"tokens\": \"Man\", \"multimodal_ner\": \"I-MISC\", \"broad_ner\": \"O\", \"wnut17_ner\": \"I-CREATIVE-WORK\", \"ritter_ner\": \"I-OTHER\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [68, 71], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 16, \"tokens\": \"\\'\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \"\\'\\'\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [71, 72], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": false, \"data_idx\": 0}, {\"index\": 17, \"tokens\": \"for\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"IN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [73, 76], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 18, \"tokens\": \"Netflix\", \"multimodal_ner\": \"B-ORG\", \"broad_ner\": \"B-ORG\", \"wnut17_ner\": \"B-CORPORATION\", \"ritter_ner\": \"B-COMPANY\", \"yodie_ner\": \"B-ORGANIZATION\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [77, 84], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 19, \"tokens\": \"The\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [86, 89], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 20, \"tokens\": \"film\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"B-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [90, 94], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 21, \"tokens\": \"has\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VBZ\", \"ritter_ccg\": \"B-VERB.STATIVE\", \"type\": \"token\", \"span\": [95, 98], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 22, \"tokens\": \"a\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [99, 100], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": false, \"data_idx\": 0}, {\"index\": 23, \"tokens\": \"$\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"SYM\", \"ark_pos\": \"A\", \"ptb_pos\": \"JJ\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [101, 102], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": true, \"data_idx\": 0}, {\"index\": 24, \"tokens\": \"200\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NUM\", \"ark_pos\": \"$\", \"ptb_pos\": \"CD\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [102, 105], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 25, \"tokens\": \"M\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [105, 106], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 26, \"tokens\": \"+\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"SYM\", \"ark_pos\": \"G\", \"ptb_pos\": \"IN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [106, 107], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": false, \"data_idx\": 0}, {\"index\": 27, \"tokens\": \"budget\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"B-NOUN.POSSESSION\", \"type\": \"token\", \"span\": [108, 114], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 28, \"tokens\": \"and\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"O\", \"ud_pos\": \"CCONJ\", \"ark_pos\": \"&\", \"ptb_pos\": \"CC\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [115, 118], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 29, \"tokens\": \"the\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [119, 122], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 30, \"tokens\": \"goal\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"B-NOUN.ATTRIBUTE\", \"type\": \"token\", \"span\": [123, 127], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 31, \"tokens\": \"is\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VBZ\", \"ritter_ccg\": \"B-VERB.STATIVE\", \"type\": \"token\", \"span\": [128, 130], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 32, \"tokens\": \"to\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-VP\", \"ud_pos\": \"PART\", \"ark_pos\": \"P\", \"ptb_pos\": \"TO\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [131, 133], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 33, \"tokens\": \"launch\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VB\", \"ritter_ccg\": \"B-VERB.PERCEPTION\", \"type\": \"token\", \"span\": [134, 140], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 34, \"tokens\": \"a\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [141, 142], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": false, \"data_idx\": 0}, {\"index\": 35, \"tokens\": \"James\", \"multimodal_ner\": \"B-PER\", \"broad_ner\": \"B-PER\", \"wnut17_ner\": \"B-PERSON\", \"ritter_ner\": \"B-PERSON\", \"yodie_ner\": \"B-PERSON\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.ARTIFACT\", \"type\": \"token\", \"span\": [143, 148], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 36, \"tokens\": \"Bond\", \"multimodal_ner\": \"I-PER\", \"broad_ner\": \"I-PER\", \"wnut17_ner\": \"I-PERSON\", \"ritter_ner\": \"I-PERSON\", \"yodie_ner\": \"I-PERSON\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.ARTIFACT\", \"type\": \"token\", \"span\": [149, 153], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 37, \"tokens\": \"-\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"O\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \":\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [153, 154], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": true, \"data_idx\": 0}, {\"index\": 38, \"tokens\": \"level\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"A\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"B-NOUN.ARTIFACT\", \"type\": \"token\", \"span\": [154, 159], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 39, \"tokens\": \"franchise\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"I-NOUN.ARTIFACT\", \"type\": \"token\", \"span\": [160, 169], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 40, \"tokens\": \"\\'\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"O\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \"\\'\\'\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [171, 172], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": true, \"data_idx\": 0}, {\"index\": 41, \"tokens\": \"For\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"IN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [172, 175], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 42, \"tokens\": \"those\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PRON\", \"ark_pos\": \"O\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [176, 181], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 43, \"tokens\": \"who\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PRON\", \"ark_pos\": \"O\", \"ptb_pos\": \"WP\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [182, 185], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 44, \"tokens\": \"were\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VBD\", \"ritter_ccg\": \"B-VERB.STATIVE\", \"type\": \"token\", \"span\": [186, 190], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 45, \"tokens\": \"fans\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NNS\", \"ritter_ccg\": \"B-NOUN.GROUP\", \"type\": \"token\", \"span\": [191, 195], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 46, \"tokens\": \"of\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"IN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [196, 198], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 47, \"tokens\": \"The\", \"multimodal_ner\": \"B-MISC\", \"broad_ner\": \"O\", \"wnut17_ner\": \"B-CREATIVE-WORK\", \"ritter_ner\": \"B-TVSHOW\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"D\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"B-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [199, 202], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 48, \"tokens\": \"Winter\", \"multimodal_ner\": \"I-MISC\", \"broad_ner\": \"O\", \"wnut17_ner\": \"I-CREATIVE-WORK\", \"ritter_ner\": \"I-TVSHOW\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [203, 209], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 49, \"tokens\": \"Soldier\", \"multimodal_ner\": \"I-MISC\", \"broad_ner\": \"O\", \"wnut17_ner\": \"I-CREATIVE-WORK\", \"ritter_ner\": \"I-TVSHOW\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PROPN\", \"ark_pos\": \"^\", \"ptb_pos\": \"NNP\", \"ritter_ccg\": \"I-NOUN.COMMUNICATION\", \"type\": \"token\", \"span\": [210, 217], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 50, \"tokens\": \"this\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"O\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [218, 222], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 51, \"tokens\": \"is\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VBZ\", \"ritter_ccg\": \"B-VERB.STATIVE\", \"type\": \"token\", \"span\": [223, 225], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 52, \"tokens\": \"us\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"PRON\", \"ark_pos\": \"O\", \"ptb_pos\": \"PRP\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [226, 228], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 53, \"tokens\": \"moving\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-VP\", \"ud_pos\": \"VERB\", \"ark_pos\": \"V\", \"ptb_pos\": \"VBG\", \"ritter_ccg\": \"B-VERB.CHANGE\", \"type\": \"token\", \"span\": [229, 235], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 54, \"tokens\": \"into\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"IN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [236, 240], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 55, \"tokens\": \"that\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [241, 245], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 56, \"tokens\": \"territory\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"B-NOUN.LOCATION\", \"type\": \"token\", \"span\": [246, 255], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 57, \"tokens\": \"in\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-PP\", \"ud_pos\": \"ADP\", \"ark_pos\": \"P\", \"ptb_pos\": \"IN\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [256, 258], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 58, \"tokens\": \"a\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"B-NP\", \"ud_pos\": \"DET\", \"ark_pos\": \"D\", \"ptb_pos\": \"DT\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [259, 260], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": false, \"data_idx\": 0}, {\"index\": 59, \"tokens\": \"real\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"ADJ\", \"ark_pos\": \"A\", \"ptb_pos\": \"JJ\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [261, 265], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 60, \"tokens\": \"-\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \":\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [265, 266], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": true, \"data_idx\": 0}, {\"index\": 61, \"tokens\": \"world\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"B-NOUN.ACT\", \"type\": \"token\", \"span\": [266, 271], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": false, \"data_idx\": 0}, {\"index\": 62, \"tokens\": \"setting\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"I-NP\", \"ud_pos\": \"NOUN\", \"ark_pos\": \"N\", \"ptb_pos\": \"NN\", \"ritter_ccg\": \"I-NOUN.ACT\", \"type\": \"token\", \"span\": [272, 279], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": false, \"no_space\": true, \"data_idx\": 0}, {\"index\": 63, \"tokens\": \"\\'\", \"multimodal_ner\": \"O\", \"broad_ner\": \"O\", \"wnut17_ner\": \"O\", \"ritter_ner\": \"O\", \"yodie_ner\": \"O\", \"ritter_chunk\": \"O\", \"ud_pos\": \"PUNCT\", \"ark_pos\": \",\", \"ptb_pos\": \"\\'\\'\", \"ritter_ccg\": \"O\", \"type\": \"token\", \"span\": [279, 280], \"is_hashtag\": false, \"is_mention\": false, \"is_url\": false, \"is_emoji\": false, \"is_emoticon\": false, \"is_symbol\": true, \"no_space\": true, \"data_idx\": 0}]}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74R9X0eykR5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "79677d5f-90b1-4e14-fa05-1fdff33fe7ca"
      },
      "source": [
        "predict_df([\"barack obama went to paris\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>barack</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 6)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>obama</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(7, 12)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBD</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(13, 17)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(18, 20)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>paris</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(21, 26)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0  barack          B-PER     B-PER  ...     False    False        0\n",
              "1   obama          I-PER     I-PER  ...     False    False        0\n",
              "2    went              O         O  ...     False    False        0\n",
              "3      to              O         O  ...     False    False        0\n",
              "4   paris          B-LOC     B-LOC  ...     False     True        0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_dpLz0FkZIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c600746e-12cd-427d-b300-85abaf15fe26"
      },
      "source": [
        "texts = [\n",
        "    \"Beautiful day in Chicago! Nice to get away from the Florida heat.\",\n",
        "    \"Barack obama went to New York.\",\n",
        "    \"obama went to Paris.\",\n",
        "    \"Facebook is a new company.\",\n",
        "    \"New york is better than SFO\",\n",
        "    \"Urbana Champaign is the best\",\n",
        "    \"urbana champaign is the best place to live and study\",\n",
        "    \"going to Ibiza\"\n",
        "]\n",
        "df = predict_df(texts)\n",
        "print(df.columns)\n",
        "for i in df.data_idx.unique():\n",
        "  display(df[df.data_idx==i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['tokens', 'multimodal_ner', 'broad_ner', 'wnut17_ner', 'ritter_ner',\n",
            "       'yodie_ner', 'ritter_chunk', 'ud_pos', 'ark_pos', 'ptb_pos',\n",
            "       'ritter_ccg', 'type', 'span', 'is_hashtag', 'is_mention', 'is_url',\n",
            "       'is_emoji', 'is_emoticon', 'is_symbol', 'no_space', 'data_idx'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beautiful</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>A</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 9)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>day</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>N</td>\n",
              "      <td>NN</td>\n",
              "      <td>B-NOUN.TIME</td>\n",
              "      <td>token</td>\n",
              "      <td>(10, 13)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(14, 16)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chicago</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(17, 24)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>!</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(24, 25)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Nice</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ADJP</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>A</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(26, 30)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>PART</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(31, 33)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>get</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VB</td>\n",
              "      <td>B-VERB.CHANGE</td>\n",
              "      <td>token</td>\n",
              "      <td>(34, 37)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>away</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ADVP</td>\n",
              "      <td>ADV</td>\n",
              "      <td>R</td>\n",
              "      <td>RB</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(38, 42)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>from</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(43, 47)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>DET</td>\n",
              "      <td>D</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(48, 51)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Florida</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(52, 59)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>heat</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>N</td>\n",
              "      <td>NN</td>\n",
              "      <td>I-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(60, 64)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(64, 65)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0   Beautiful              O         O  ...     False    False        0\n",
              "1         day              O         O  ...     False    False        0\n",
              "2          in              O         O  ...     False    False        0\n",
              "3     Chicago          B-LOC     B-LOC  ...     False     True        0\n",
              "4           !              O         O  ...      True    False        0\n",
              "5        Nice              O         O  ...     False    False        0\n",
              "6          to              O         O  ...     False    False        0\n",
              "7         get              O         O  ...     False    False        0\n",
              "8        away              O         O  ...     False    False        0\n",
              "9        from              O         O  ...     False    False        0\n",
              "10        the              O         O  ...     False    False        0\n",
              "11    Florida          B-LOC     B-LOC  ...     False    False        0\n",
              "12       heat              O         O  ...     False     True        0\n",
              "13          .              O         O  ...      True     True        0\n",
              "\n",
              "[14 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barack</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 6)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>obama</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(7, 12)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>went</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBD</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(13, 17)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(18, 20)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>New</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(21, 24)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>York</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOCATION</td>\n",
              "      <td>I-GEO-LOC</td>\n",
              "      <td>I-GEO-LOC</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(25, 29)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(29, 30)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0  Barack          B-PER     B-PER  ...     False    False        1\n",
              "1   obama          I-PER     I-PER  ...     False    False        1\n",
              "2    went              O         O  ...     False    False        1\n",
              "3      to              O         O  ...     False    False        1\n",
              "4     New          B-LOC     B-LOC  ...     False    False        1\n",
              "5    York          I-LOC     I-LOC  ...     False     True        1\n",
              "6       .              O         O  ...      True     True        1\n",
              "\n",
              "[7 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>obama</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 5)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>went</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBD</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(6, 10)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(11, 13)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Paris</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(14, 19)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(19, 20)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0  obama          B-PER         O  ...     False    False        2\n",
              "1   went              O         O  ...     False    False        2\n",
              "2     to              O         O  ...     False    False        2\n",
              "3  Paris          B-LOC     B-LOC  ...     False     True        2\n",
              "4      .              O         O  ...      True     True        2\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Facebook</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-CORPORATION</td>\n",
              "      <td>B-COMPANY</td>\n",
              "      <td>B-COMPANY</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.COMMUNICATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 8)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>B-VERB.STATIVE</td>\n",
              "      <td>token</td>\n",
              "      <td>(9, 11)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>DET</td>\n",
              "      <td>D</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(12, 13)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>A</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(14, 17)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>company</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>N</td>\n",
              "      <td>NN</td>\n",
              "      <td>B-NOUN.COMMUNICATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(18, 25)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(25, 26)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0  Facebook          B-ORG     B-ORG  ...     False    False        3\n",
              "1        is              O         O  ...     False    False        3\n",
              "2         a              O         O  ...      True    False        3\n",
              "3       new              O         O  ...     False    False        3\n",
              "4   company              O         O  ...     False     True        3\n",
              "5         .              O         O  ...      True     True        3\n",
              "\n",
              "[6 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>New</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 3)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>york</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOCATION</td>\n",
              "      <td>I-GEO-LOC</td>\n",
              "      <td>I-LOCATION</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(4, 8)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>B-VERB.STATIVE</td>\n",
              "      <td>token</td>\n",
              "      <td>(9, 11)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>better</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ADJP</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>A</td>\n",
              "      <td>JJR</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(12, 18)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>than</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(19, 23)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SFO</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-CORPORATION</td>\n",
              "      <td>B-COMPANY</td>\n",
              "      <td>B-COMPANY</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.GROUP</td>\n",
              "      <td>token</td>\n",
              "      <td>(24, 27)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0     New          B-LOC     B-LOC  ...     False    False        4\n",
              "1    york          I-LOC     I-LOC  ...     False    False        4\n",
              "2      is              O         O  ...     False    False        4\n",
              "3  better              O         O  ...     False    False        4\n",
              "4    than              O         O  ...     False    False        4\n",
              "5     SFO          B-ORG     B-ORG  ...     False     True        4\n",
              "\n",
              "[6 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Urbana</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 6)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Champaign</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>I-LOCATION</td>\n",
              "      <td>I-GEO-LOC</td>\n",
              "      <td>I-LOCATION</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(7, 16)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>B-VERB.STATIVE</td>\n",
              "      <td>token</td>\n",
              "      <td>(17, 19)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>DET</td>\n",
              "      <td>D</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(20, 23)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>A</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(24, 28)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0     Urbana          B-LOC     B-LOC  ...     False    False        5\n",
              "1  Champaign          I-LOC     I-LOC  ...     False    False        5\n",
              "2         is              O         O  ...     False    False        5\n",
              "3        the              O         O  ...     False    False        5\n",
              "4       best              O         O  ...     False     True        5\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>urbana</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-PERSON</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 6)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>champaign</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-PERSON</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-NOUN.PERSON</td>\n",
              "      <td>token</td>\n",
              "      <td>(7, 16)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>B-VERB.STATIVE</td>\n",
              "      <td>token</td>\n",
              "      <td>(17, 19)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>DET</td>\n",
              "      <td>D</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(20, 23)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>A</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(24, 28)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>place</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-NP</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>N</td>\n",
              "      <td>NN</td>\n",
              "      <td>B-NOUN.STATE</td>\n",
              "      <td>token</td>\n",
              "      <td>(29, 34)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>PART</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(35, 37)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>live</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>I-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VB</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(38, 42)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>&amp;</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(43, 46)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>study</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VB</td>\n",
              "      <td>B-NOUN.ACT</td>\n",
              "      <td>token</td>\n",
              "      <td>(47, 52)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0     urbana          B-PER     B-PER  ...     False    False        6\n",
              "1  champaign          I-PER     I-PER  ...     False    False        6\n",
              "2         is              O         O  ...     False    False        6\n",
              "3        the              O         O  ...     False    False        6\n",
              "4       best              O         O  ...     False    False        6\n",
              "5      place              O         O  ...     False    False        6\n",
              "6         to              O         O  ...     False    False        6\n",
              "7       live              O         O  ...     False    False        6\n",
              "8        and              O         O  ...     False    False        6\n",
              "9      study              O         O  ...     False     True        6\n",
              "\n",
              "[10 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>multimodal_ner</th>\n",
              "      <th>broad_ner</th>\n",
              "      <th>wnut17_ner</th>\n",
              "      <th>ritter_ner</th>\n",
              "      <th>yodie_ner</th>\n",
              "      <th>ritter_chunk</th>\n",
              "      <th>ud_pos</th>\n",
              "      <th>ark_pos</th>\n",
              "      <th>ptb_pos</th>\n",
              "      <th>ritter_ccg</th>\n",
              "      <th>type</th>\n",
              "      <th>span</th>\n",
              "      <th>is_hashtag</th>\n",
              "      <th>is_mention</th>\n",
              "      <th>is_url</th>\n",
              "      <th>is_emoji</th>\n",
              "      <th>is_emoticon</th>\n",
              "      <th>is_symbol</th>\n",
              "      <th>no_space</th>\n",
              "      <th>data_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>going</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-VP</td>\n",
              "      <td>VERB</td>\n",
              "      <td>V</td>\n",
              "      <td>VBG</td>\n",
              "      <td>B-VERB.MOTION</td>\n",
              "      <td>token</td>\n",
              "      <td>(0, 5)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-PP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>P</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "      <td>token</td>\n",
              "      <td>(6, 8)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ibiza</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOCATION</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-GEO-LOC</td>\n",
              "      <td>B-NP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>^</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-NOUN.LOCATION</td>\n",
              "      <td>token</td>\n",
              "      <td>(9, 14)</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  tokens multimodal_ner broad_ner  ... is_symbol no_space data_idx\n",
              "0  going              O         O  ...     False    False        7\n",
              "1     to              O         O  ...     False    False        7\n",
              "2  Ibiza          B-LOC     B-LOC  ...     False     True        7\n",
              "\n",
              "[3 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhGh2AkuwX0U",
        "colab_type": "text"
      },
      "source": [
        "## Multi task Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3ua6GI-kb_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from SocialMediaIE.predictor.model_predictor_classification import run, get_args, PREFIX, get_model_output, output_to_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6-FK-Rjwep6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "34db05ee-064f-4edf-c75a-2144e5596e23"
      },
      "source": [
        "SERIALIZATION_DIR = Path(\"./SocialMediaIE/data/models_classification/all_multitask_shared_bilstm_l2_0_lr_1e-3/\")\n",
        "args = get_args(PREFIX, SERIALIZATION_DIR)\n",
        "args = args._replace(\n",
        "    dataset_paths_file = \"./SocialMediaIE/experiments/all_classification_dataset_paths.json\",\n",
        "    cuda=False # Very important as not running on GPU\n",
        ")\n",
        "args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelArgument(task=['founta_abusive', 'waseem_abusive', 'sarcasm_uncertainity', 'veridicality_uncertainity', 'semeval_sentiment', 'clarin_sentiment', 'politics_sentiment', 'other_sentiment'], dataset_paths_file='./SocialMediaIE/experiments/all_classification_dataset_paths.json', dataset_path_prefix='/experiments', model_dir='/content/SocialMediaIE/data/models_classification/all_multitask_shared_bilstm_l2_0_lr_1e-3', clean_model_dir=True, proj_dim=100, hidden_dim=100, encoder_type='bilstm', multi_task_mode='shared', dropout=0.5, lr=0.001, weight_decay=0.0, batch_size=16, epochs=10, patience=3, cuda=False, test_mode=True, residual_connection=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D5D6Hk_wgUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "34d4b303-b7bb-4bb9-a392-6a0fd9732d20"
      },
      "source": [
        "TASKS, vocab, model, readers, test_iterator = run(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHu2zs74wifu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    objects = [get_match_object(match) for match in get_match_iter(text)]\n",
        "    n = len(objects)\n",
        "    cleaned_objects = []\n",
        "    for i, obj in enumerate(objects):\n",
        "        obj[\"no_space\"] = True\n",
        "        if obj[\"type\"] == \"space\":\n",
        "            continue\n",
        "        if i < n-1 and objects[i+1][\"type\"] == \"space\":\n",
        "            obj[\"no_space\"] = False\n",
        "        cleaned_objects.append(obj)\n",
        "    keys = cleaned_objects[0].keys()\n",
        "    final_sequences = {}\n",
        "    for k in keys:\n",
        "        final_sequences[k] = [obj[k] for obj in cleaned_objects]\n",
        "    return final_sequences\n",
        "\n",
        "def predict_json(texts=None):\n",
        "    # Empty cache to ensure larger batch can be loaded for testing\n",
        "    if texts:\n",
        "        data = [tokenize(text) for text in texts]\n",
        "    else:\n",
        "        text = \"Barack Obama went to Paris and never returned to the USA.\"\n",
        "        text1 = \"Stan Lee was a legend who developed Spiderman and the Avengers movie series.\"\n",
        "        text2 = \"I just learned about donald drumph through john oliver. #JohnOliverShow such an awesome show.\"\n",
        "        texts = [text, text1, text2]\n",
        "        data = [tokenize(text) for text in texts]\n",
        "    torch.cuda.empty_cache()\n",
        "    tokens = [obj[\"value\"] for obj in data]\n",
        "    output = list(get_model_output(model, tokens, args, readers, vocab, test_iterator))\n",
        "\n",
        "    output_json = [\n",
        "                   {\n",
        "                       \"classification\": dict(\n",
        "                           text=text, \n",
        "                           doc_idx=i, \n",
        "                           **output_to_json(tokens[i], output[i], vocab))\n",
        "                       }\n",
        "                   for i, text in enumerate(texts)\n",
        "                   ]\n",
        "    return output_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMiubnPHwrs1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03583652-ac98-438b-fea2-ab6cba382048"
      },
      "source": [
        "output_json = predict_json()\n",
        "for d in output_json:\n",
        "  display(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.377587229013443,\n",
              "   'neutral': 0.5517898797988892,\n",
              "   'positive': 0.07062286883592606},\n",
              "  'doc_idx': 0,\n",
              "  'founta_abusive': {'abusive': 0.018016666173934937,\n",
              "   'hateful': 0.04844215139746666,\n",
              "   'normal': 0.9298549294471741,\n",
              "   'spam': 0.003686218522489071},\n",
              "  'other_sentiment': {'negative': 0.3766862452030182,\n",
              "   'neutral': 0.5350586175918579,\n",
              "   'positive': 0.0882551297545433},\n",
              "  'politics_sentiment': {'negative': 0.4884316921234131,\n",
              "   'neutral': 0.40015631914138794,\n",
              "   'positive': 0.11141200363636017},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9953067898750305,\n",
              "   'sarcasm': 0.0046932087279856205},\n",
              "  'semeval_sentiment': {'negative': 0.39029017090797424,\n",
              "   'neutral': 0.5236590504646301,\n",
              "   'positive': 0.08605076372623444},\n",
              "  'text': 'Barack Obama went to Paris and never returned to the USA.',\n",
              "  'tokens': ['Barack',\n",
              "   'Obama',\n",
              "   'went',\n",
              "   'to',\n",
              "   'Paris',\n",
              "   'and',\n",
              "   'never',\n",
              "   'returned',\n",
              "   'to',\n",
              "   'the',\n",
              "   'USA',\n",
              "   '.'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.04782041162252426,\n",
              "   'definitely_yes': 0.30803143978118896,\n",
              "   'probably_no': 0.07321972399950027,\n",
              "   'probably_yes': 0.11583792418241501,\n",
              "   'uncertain': 0.4550904631614685},\n",
              "  'waseem_abusive': {'none': 0.9588715434074402,\n",
              "   'racism': 0.015386759303510189,\n",
              "   'sexism': 0.025741688907146454}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.0912058874964714,\n",
              "   'neutral': 0.5898062586784363,\n",
              "   'positive': 0.3189878761768341},\n",
              "  'doc_idx': 1,\n",
              "  'founta_abusive': {'abusive': 0.005538747180253267,\n",
              "   'hateful': 0.0044571938924491405,\n",
              "   'normal': 0.9843591451644897,\n",
              "   'spam': 0.005644865799695253},\n",
              "  'other_sentiment': {'negative': 0.12104222178459167,\n",
              "   'neutral': 0.545995831489563,\n",
              "   'positive': 0.3329619765281677},\n",
              "  'politics_sentiment': {'negative': 0.584104597568512,\n",
              "   'neutral': 0.33796781301498413,\n",
              "   'positive': 0.0779276192188263},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9936363697052002,\n",
              "   'sarcasm': 0.0063636587001383305},\n",
              "  'semeval_sentiment': {'negative': 0.025512298569083214,\n",
              "   'neutral': 0.48244330286979675,\n",
              "   'positive': 0.4920443892478943},\n",
              "  'text': 'Stan Lee was a legend who developed Spiderman and the Avengers movie series.',\n",
              "  'tokens': ['Stan',\n",
              "   'Lee',\n",
              "   'was',\n",
              "   'a',\n",
              "   'legend',\n",
              "   'who',\n",
              "   'developed',\n",
              "   'Spiderman',\n",
              "   'and',\n",
              "   'the',\n",
              "   'Avengers',\n",
              "   'movie',\n",
              "   'series',\n",
              "   '.'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.034236788749694824,\n",
              "   'definitely_yes': 0.19472849369049072,\n",
              "   'probably_no': 0.03524045646190643,\n",
              "   'probably_yes': 0.29833394289016724,\n",
              "   'uncertain': 0.4374602735042572},\n",
              "  'waseem_abusive': {'none': 0.8772116303443909,\n",
              "   'racism': 0.010285227559506893,\n",
              "   'sexism': 0.11250307410955429}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.014927796088159084,\n",
              "   'neutral': 0.03387293219566345,\n",
              "   'positive': 0.9511992335319519},\n",
              "  'doc_idx': 2,\n",
              "  'founta_abusive': {'abusive': 0.0244298093020916,\n",
              "   'hateful': 0.013859059661626816,\n",
              "   'normal': 0.957321286201477,\n",
              "   'spam': 0.004389943089336157},\n",
              "  'other_sentiment': {'negative': 0.01228583138436079,\n",
              "   'neutral': 0.02622193656861782,\n",
              "   'positive': 0.9614921808242798},\n",
              "  'politics_sentiment': {'negative': 0.2683788239955902,\n",
              "   'neutral': 0.20243778824806213,\n",
              "   'positive': 0.5291833877563477},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9019794464111328,\n",
              "   'sarcasm': 0.09802061319351196},\n",
              "  'semeval_sentiment': {'negative': 0.0021598406601697206,\n",
              "   'neutral': 0.009135011583566666,\n",
              "   'positive': 0.9887052178382874},\n",
              "  'text': 'I just learned about donald drumph through john oliver. #JohnOliverShow such an awesome show.',\n",
              "  'tokens': ['I',\n",
              "   'just',\n",
              "   'learned',\n",
              "   'about',\n",
              "   'donald',\n",
              "   'drumph',\n",
              "   'through',\n",
              "   'john',\n",
              "   'oliver',\n",
              "   '.',\n",
              "   '#JohnOliverShow',\n",
              "   'such',\n",
              "   'an',\n",
              "   'awesome',\n",
              "   'show',\n",
              "   '.'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.037549715489149094,\n",
              "   'definitely_yes': 0.18402868509292603,\n",
              "   'probably_no': 0.008736047893762589,\n",
              "   'probably_yes': 0.33069881796836853,\n",
              "   'uncertain': 0.4389866292476654},\n",
              "  'waseem_abusive': {'none': 0.8648111820220947,\n",
              "   'racism': 0.002863893751055002,\n",
              "   'sexism': 0.13232487440109253}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gamNvsxwuW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6ef1bf49-49ef-468a-b8da-788ef61eb0cb"
      },
      "source": [
        "json.dumps(predict_json([\"barack obama went to paris\"])[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'{\"classification\": {\"text\": \"barack obama went to paris\", \"doc_idx\": 0, \"tokens\": [\"barack\", \"obama\", \"went\", \"to\", \"paris\"], \"founta_abusive\": {\"normal\": 0.9031787514686584, \"spam\": 0.013646047562360764, \"abusive\": 0.05717331916093826, \"hateful\": 0.0260018240660429}, \"waseem_abusive\": {\"none\": 0.9790737628936768, \"sexism\": 0.01925569958984852, \"racism\": 0.001670498983003199}, \"sarcasm_uncertainity\": {\"not_sarcasm\": 0.9918217062950134, \"sarcasm\": 0.008178316056728363}, \"veridicality_uncertainity\": {\"uncertain\": 0.5396470427513123, \"definitely_yes\": 0.2180899977684021, \"probably_yes\": 0.1622510403394699, \"probably_no\": 0.055232349783182144, \"definitely_no\": 0.024779530242085457}, \"semeval_sentiment\": {\"positive\": 0.20253653824329376, \"neutral\": 0.6687340140342712, \"negative\": 0.1287294328212738}, \"clarin_sentiment\": {\"neutral\": 0.5424699783325195, \"positive\": 0.15769727528095245, \"negative\": 0.2998327910900116}, \"politics_sentiment\": {\"negative\": 0.2542945146560669, \"neutral\": 0.6239544153213501, \"positive\": 0.1217510998249054}, \"other_sentiment\": {\"negative\": 0.3311120271682739, \"neutral\": 0.6013840436935425, \"positive\": 0.06750389188528061}}}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmL0vVTZB4K2",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the output:\n",
        "\n",
        "You can copy the JSON output of the above cell and paste it at (and click Visualize): https://codepen.io/napsternxg/full/YzwRqEb to see a pretty representation of the output as shown in the presentation. \n",
        "\n",
        "If you hover over the output of the above cell, Colab will show you how to copy it to clipboard. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij6I5LYKw0LL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a73cb1c-4fad-4e87-d1f5-3b334edfe362"
      },
      "source": [
        "texts = [\n",
        "    \"Beautiful day in Chicago! Nice to get away from the Florida heat.\",\n",
        "    \"Barack obama went to New York.\",\n",
        "    \"obama went to Paris.\",\n",
        "    \"Facebook is a new company.\",\n",
        "    \"New york is better than SFO\",\n",
        "    \"Urbana Champaign is the best\",\n",
        "    \"urbana champaign is the best place to live and study\",\n",
        "    \"going to Ibiza\"\n",
        "]\n",
        "output_json = predict_json(texts)\n",
        "for text, output in zip(texts, output_json):\n",
        "  print(f\"Text: {text}\")\n",
        "  display(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: Beautiful day in Chicago! Nice to get away from the Florida heat.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.023805510252714157,\n",
              "   'neutral': 0.02780826762318611,\n",
              "   'positive': 0.9483862519264221},\n",
              "  'doc_idx': 0,\n",
              "  'founta_abusive': {'abusive': 0.019499467685818672,\n",
              "   'hateful': 0.011274510063230991,\n",
              "   'normal': 0.963321328163147,\n",
              "   'spam': 0.005904657766222954},\n",
              "  'other_sentiment': {'negative': 0.08318859338760376,\n",
              "   'neutral': 0.03771861642599106,\n",
              "   'positive': 0.879092812538147},\n",
              "  'politics_sentiment': {'negative': 0.15089169144630432,\n",
              "   'neutral': 0.17477740347385406,\n",
              "   'positive': 0.6743309497833252},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9279211163520813,\n",
              "   'sarcasm': 0.0720788836479187},\n",
              "  'semeval_sentiment': {'negative': 0.0018857510294765234,\n",
              "   'neutral': 0.010031498968601227,\n",
              "   'positive': 0.9880827069282532},\n",
              "  'text': 'Beautiful day in Chicago! Nice to get away from the Florida heat.',\n",
              "  'tokens': ['Beautiful',\n",
              "   'day',\n",
              "   'in',\n",
              "   'Chicago',\n",
              "   '!',\n",
              "   'Nice',\n",
              "   'to',\n",
              "   'get',\n",
              "   'away',\n",
              "   'from',\n",
              "   'the',\n",
              "   'Florida',\n",
              "   'heat',\n",
              "   '.'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.0599665567278862,\n",
              "   'definitely_yes': 0.33538761734962463,\n",
              "   'probably_no': 0.014954348094761372,\n",
              "   'probably_yes': 0.27601924538612366,\n",
              "   'uncertain': 0.3136722147464752},\n",
              "  'waseem_abusive': {'none': 0.989596426486969,\n",
              "   'racism': 0.003064533229917288,\n",
              "   'sexism': 0.007339121773838997}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: Barack obama went to New York.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.11956237256526947,\n",
              "   'neutral': 0.76449054479599,\n",
              "   'positive': 0.11594709753990173},\n",
              "  'doc_idx': 1,\n",
              "  'founta_abusive': {'abusive': 0.016656825318932533,\n",
              "   'hateful': 0.01351882517337799,\n",
              "   'normal': 0.9632956981658936,\n",
              "   'spam': 0.006528662983328104},\n",
              "  'other_sentiment': {'negative': 0.17126032710075378,\n",
              "   'neutral': 0.7576371431350708,\n",
              "   'positive': 0.07110244035720825},\n",
              "  'politics_sentiment': {'negative': 0.16021940112113953,\n",
              "   'neutral': 0.5975267291069031,\n",
              "   'positive': 0.24225382506847382},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9977854490280151,\n",
              "   'sarcasm': 0.002214545151218772},\n",
              "  'semeval_sentiment': {'negative': 0.053348273038864136,\n",
              "   'neutral': 0.8261353969573975,\n",
              "   'positive': 0.1205163449048996},\n",
              "  'text': 'Barack obama went to New York.',\n",
              "  'tokens': ['Barack', 'obama', 'went', 'to', 'New', 'York', '.'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.04828560724854469,\n",
              "   'definitely_yes': 0.304178386926651,\n",
              "   'probably_no': 0.0741635262966156,\n",
              "   'probably_yes': 0.11380760371685028,\n",
              "   'uncertain': 0.45956480503082275},\n",
              "  'waseem_abusive': {'none': 0.9844968318939209,\n",
              "   'racism': 0.0024762225802987814,\n",
              "   'sexism': 0.013027023524045944}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: obama went to Paris.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.11863768845796585,\n",
              "   'neutral': 0.6891959309577942,\n",
              "   'positive': 0.19216644763946533},\n",
              "  'doc_idx': 2,\n",
              "  'founta_abusive': {'abusive': 0.013510918244719505,\n",
              "   'hateful': 0.01179617177695036,\n",
              "   'normal': 0.9691336750984192,\n",
              "   'spam': 0.005559186916798353},\n",
              "  'other_sentiment': {'negative': 0.21773962676525116,\n",
              "   'neutral': 0.6785171627998352,\n",
              "   'positive': 0.10374321788549423},\n",
              "  'politics_sentiment': {'negative': 0.1848520040512085,\n",
              "   'neutral': 0.5232776999473572,\n",
              "   'positive': 0.2918702960014343},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9962672591209412,\n",
              "   'sarcasm': 0.003732779063284397},\n",
              "  'semeval_sentiment': {'negative': 0.06244625151157379,\n",
              "   'neutral': 0.7494382858276367,\n",
              "   'positive': 0.18811547756195068},\n",
              "  'text': 'obama went to Paris.',\n",
              "  'tokens': ['obama', 'went', 'to', 'Paris', '.'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.045336417853832245,\n",
              "   'definitely_yes': 0.32768377661705017,\n",
              "   'probably_no': 0.05545300990343094,\n",
              "   'probably_yes': 0.1186356246471405,\n",
              "   'uncertain': 0.4528912305831909},\n",
              "  'waseem_abusive': {'none': 0.9905763864517212,\n",
              "   'racism': 0.002730048494413495,\n",
              "   'sexism': 0.006693535950034857}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: Facebook is a new company.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.23051410913467407,\n",
              "   'neutral': 0.5204728245735168,\n",
              "   'positive': 0.24901309609413147},\n",
              "  'doc_idx': 3,\n",
              "  'founta_abusive': {'abusive': 0.019015135243535042,\n",
              "   'hateful': 0.012292065657675266,\n",
              "   'normal': 0.9350468516349792,\n",
              "   'spam': 0.03364601358771324},\n",
              "  'other_sentiment': {'negative': 0.47664013504981995,\n",
              "   'neutral': 0.314541757106781,\n",
              "   'positive': 0.20881810784339905},\n",
              "  'politics_sentiment': {'negative': 0.39994916319847107,\n",
              "   'neutral': 0.4875374138355255,\n",
              "   'positive': 0.11251337826251984},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9590727090835571,\n",
              "   'sarcasm': 0.040927253663539886},\n",
              "  'semeval_sentiment': {'negative': 0.09727726131677628,\n",
              "   'neutral': 0.4892808794975281,\n",
              "   'positive': 0.41344183683395386},\n",
              "  'text': 'Facebook is a new company.',\n",
              "  'tokens': ['Facebook', 'is', 'a', 'new', 'company', '.'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.038073983043432236,\n",
              "   'definitely_yes': 0.24917195737361908,\n",
              "   'probably_no': 0.05484198033809662,\n",
              "   'probably_yes': 0.26808446645736694,\n",
              "   'uncertain': 0.3898276388645172},\n",
              "  'waseem_abusive': {'none': 0.9807422161102295,\n",
              "   'racism': 0.004714523907750845,\n",
              "   'sexism': 0.014543279074132442}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: New york is better than SFO\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.49178194999694824,\n",
              "   'neutral': 0.20879890024662018,\n",
              "   'positive': 0.29941919445991516},\n",
              "  'doc_idx': 4,\n",
              "  'founta_abusive': {'abusive': 0.041987065225839615,\n",
              "   'hateful': 0.030969295650720596,\n",
              "   'normal': 0.90111243724823,\n",
              "   'spam': 0.025931205600500107},\n",
              "  'other_sentiment': {'negative': 0.36167532205581665,\n",
              "   'neutral': 0.32706478238105774,\n",
              "   'positive': 0.3112598955631256},\n",
              "  'politics_sentiment': {'negative': 0.45212510228157043,\n",
              "   'neutral': 0.41449111700057983,\n",
              "   'positive': 0.13338378071784973},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.946239709854126,\n",
              "   'sarcasm': 0.053760282695293427},\n",
              "  'semeval_sentiment': {'negative': 0.22308166325092316,\n",
              "   'neutral': 0.20926184952259064,\n",
              "   'positive': 0.5676565170288086},\n",
              "  'text': 'New york is better than SFO',\n",
              "  'tokens': ['New', 'york', 'is', 'better', 'than', 'SFO'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.03027193807065487,\n",
              "   'definitely_yes': 0.25793740153312683,\n",
              "   'probably_no': 0.029707206413149834,\n",
              "   'probably_yes': 0.32223159074783325,\n",
              "   'uncertain': 0.35985174775123596},\n",
              "  'waseem_abusive': {'none': 0.9544270038604736,\n",
              "   'racism': 0.0016567305428907275,\n",
              "   'sexism': 0.043916307389736176}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: Urbana Champaign is the best\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.007267965003848076,\n",
              "   'neutral': 0.18252544105052948,\n",
              "   'positive': 0.8102065324783325},\n",
              "  'doc_idx': 5,\n",
              "  'founta_abusive': {'abusive': 0.00602313969284296,\n",
              "   'hateful': 0.003372754668816924,\n",
              "   'normal': 0.9841240048408508,\n",
              "   'spam': 0.006480109412223101},\n",
              "  'other_sentiment': {'negative': 0.014329152181744576,\n",
              "   'neutral': 0.19069431722164154,\n",
              "   'positive': 0.794976532459259},\n",
              "  'politics_sentiment': {'negative': 0.015802301466464996,\n",
              "   'neutral': 0.11866085231304169,\n",
              "   'positive': 0.8655368089675903},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9982795715332031,\n",
              "   'sarcasm': 0.0017203980823978782},\n",
              "  'semeval_sentiment': {'negative': 0.0018378273816779256,\n",
              "   'neutral': 0.035411033779382706,\n",
              "   'positive': 0.9627512097358704},\n",
              "  'text': 'Urbana Champaign is the best',\n",
              "  'tokens': ['Urbana', 'Champaign', 'is', 'the', 'best'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.0281850453466177,\n",
              "   'definitely_yes': 0.434145987033844,\n",
              "   'probably_no': 0.02106301486492157,\n",
              "   'probably_yes': 0.1870717704296112,\n",
              "   'uncertain': 0.329534113407135},\n",
              "  'waseem_abusive': {'none': 0.9532039165496826,\n",
              "   'racism': 0.006746443919837475,\n",
              "   'sexism': 0.040049582719802856}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: urbana champaign is the best place to live and study\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.00990063976496458,\n",
              "   'neutral': 0.1627143919467926,\n",
              "   'positive': 0.827384889125824},\n",
              "  'doc_idx': 6,\n",
              "  'founta_abusive': {'abusive': 0.010682592168450356,\n",
              "   'hateful': 0.0045213340781629086,\n",
              "   'normal': 0.9668214321136475,\n",
              "   'spam': 0.017974641174077988},\n",
              "  'other_sentiment': {'negative': 0.030320458114147186,\n",
              "   'neutral': 0.1826387494802475,\n",
              "   'positive': 0.7870407700538635},\n",
              "  'politics_sentiment': {'negative': 0.03515143319964409,\n",
              "   'neutral': 0.21806727349758148,\n",
              "   'positive': 0.7467812895774841},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9911916851997375,\n",
              "   'sarcasm': 0.008808319456875324},\n",
              "  'semeval_sentiment': {'negative': 0.0024788370355963707,\n",
              "   'neutral': 0.045599620789289474,\n",
              "   'positive': 0.9519215822219849},\n",
              "  'text': 'urbana champaign is the best place to live and study',\n",
              "  'tokens': ['urbana',\n",
              "   'champaign',\n",
              "   'is',\n",
              "   'the',\n",
              "   'best',\n",
              "   'place',\n",
              "   'to',\n",
              "   'live',\n",
              "   'and',\n",
              "   'study'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.043029025197029114,\n",
              "   'definitely_yes': 0.3990635573863983,\n",
              "   'probably_no': 0.03076864778995514,\n",
              "   'probably_yes': 0.14199885725975037,\n",
              "   'uncertain': 0.3851398825645447},\n",
              "  'waseem_abusive': {'none': 0.9832895994186401,\n",
              "   'racism': 0.0030717398039996624,\n",
              "   'sexism': 0.013638623058795929}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Text: going to Ibiza\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'classification': {'clarin_sentiment': {'negative': 0.07858170568943024,\n",
              "   'neutral': 0.660545289516449,\n",
              "   'positive': 0.26087304949760437},\n",
              "  'doc_idx': 7,\n",
              "  'founta_abusive': {'abusive': 0.07335348427295685,\n",
              "   'hateful': 0.057870738208293915,\n",
              "   'normal': 0.7353984117507935,\n",
              "   'spam': 0.13337735831737518},\n",
              "  'other_sentiment': {'negative': 0.14290709793567657,\n",
              "   'neutral': 0.6826916933059692,\n",
              "   'positive': 0.17440129816532135},\n",
              "  'politics_sentiment': {'negative': 0.16251078248023987,\n",
              "   'neutral': 0.6454045176506042,\n",
              "   'positive': 0.1920846700668335},\n",
              "  'sarcasm_uncertainity': {'not_sarcasm': 0.9907566905021667,\n",
              "   'sarcasm': 0.009243348613381386},\n",
              "  'semeval_sentiment': {'negative': 0.029730720445513725,\n",
              "   'neutral': 0.5934746265411377,\n",
              "   'positive': 0.376794695854187},\n",
              "  'text': 'going to Ibiza',\n",
              "  'tokens': ['going', 'to', 'Ibiza'],\n",
              "  'veridicality_uncertainity': {'definitely_no': 0.04334722459316254,\n",
              "   'definitely_yes': 0.3249450922012329,\n",
              "   'probably_no': 0.07097399979829788,\n",
              "   'probably_yes': 0.18138942122459412,\n",
              "   'uncertain': 0.37934422492980957},\n",
              "  'waseem_abusive': {'none': 0.9546189308166504,\n",
              "   'racism': 0.014279968105256557,\n",
              "   'sexism': 0.031101075932383537}}}"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKKPBbagAHS4",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing outputs\n",
        "\n",
        "Embeds the visualization page https://codepen.io/napsternxg/full/YzwRqEb as an iframe.\n",
        "\n",
        "Copy paste model output JSON from above into the text area and click **Visualize**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgyX0YLOAJ3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "a7489bb6-90f7-4f8e-d389-aa832c1fb77c"
      },
      "source": [
        "%%html\n",
        "<p class=\"codepen\" data-height=\"750\" data-theme-id=\"dark\" data-default-tab=\"result\" data-user=\"napsternxg\" data-slug-hash=\"YzwRqEb\" style=\"height: 750px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid; margin: 1em 0; padding: 1em;\" data-pen-title=\"SocialMediaIE Classifier Tagger render\">\n",
        "  <span>See the Pen <a href=\"https://codepen.io/napsternxg/pen/YzwRqEb\">\n",
        "  SocialMediaIE Classifier Tagger render</a> by Shubhanshu Mishra (<a href=\"https://codepen.io/napsternxg\">@napsternxg</a>)\n",
        "  on <a href=\"https://codepen.io\">CodePen</a>.</span>\n",
        "</p>\n",
        "<script async src=\"https://static.codepen.io/assets/embed/ei.js\"></script>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p class=\"codepen\" data-height=\"750\" data-theme-id=\"dark\" data-default-tab=\"result\" data-user=\"napsternxg\" data-slug-hash=\"YzwRqEb\" style=\"height: 750px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid; margin: 1em 0; padding: 1em;\" data-pen-title=\"SocialMediaIE Classifier Tagger render\">\n",
              "  <span>See the Pen <a href=\"https://codepen.io/napsternxg/pen/YzwRqEb\">\n",
              "  SocialMediaIE Classifier Tagger render</a> by Shubhanshu Mishra (<a href=\"https://codepen.io/napsternxg\">@napsternxg</a>)\n",
              "  on <a href=\"https://codepen.io\">CodePen</a>.</span>\n",
              "</p>\n",
              "<script async src=\"https://static.codepen.io/assets/embed/ei.js\"></script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54ks1fR9A2S-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}